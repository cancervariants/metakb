{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import ast\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variant_ids_we_cant_get = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"metakb.log.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get total counts for CIViC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CIViC EIDs: 9456\n",
      "Total approved CIViC EIDs: 4022\n",
      "Total approved predictive CIViC EIDs: 2478\n",
      "Total CIViC Variants: 3362\n",
      "Total CIViC Variants in approved predictive CIViC EIDs 944\n"
     ]
    }
   ],
   "source": [
    "with open(\"metakb_log_analysis.log\", \"w+\") as wf:\n",
    "    with open(\"metakb.log\", \"r\") as rf:\n",
    "        for line in rf:\n",
    "            if \"metakb\" in line:\n",
    "                wf.write(line)\n",
    "\n",
    "                if \"TOTAL\" in line:\n",
    "                    count = int(line.split(\": \")[-1])\n",
    "                    if \"CIViC Variants in Approved Predictive Evidence\" in line:\n",
    "                          total_vids_approved_predictive = count\n",
    "                    elif \"approved CIViC EIDs\" in line:\n",
    "                        total_approved_eids = count\n",
    "                    elif \"approved predictive CIViC EIDs\" in line:\n",
    "                        total_approved_predictive_eids = count\n",
    "                    elif \"CIViC EIDs\" in line:\n",
    "                        total_eids = count\n",
    "                    elif \"CIViC Variants\" in line:\n",
    "                        total_vids = count\n",
    "\n",
    "print(\"Total CIViC EIDs:\", total_eids)\n",
    "print(\"Total approved CIViC EIDs:\", total_approved_eids)\n",
    "print(\"Total approved predictive CIViC EIDs:\", total_approved_predictive_eids)\n",
    "print(\"Total CIViC Variants:\", total_vids)\n",
    "print(\"Total CIViC Variants in approved predictive CIViC EIDs\", total_vids_approved_predictive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of EIDs we could capture: 26.20558375634518\n",
      "% of VIDs we could capture: 28.078524687685903\n"
     ]
    }
   ],
   "source": [
    "print(\"% of EIDs we could capture:\", total_approved_predictive_eids / total_eids * 100)\n",
    "print(\"% of VIDs we could capture:\", total_vids_approved_predictive / total_vids * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation Normalizer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of CIViC VIDs we can't normalize: 227\n",
      "% of CIViC VIDs we can't normalize: 24.046610169491526\n"
     ]
    }
   ],
   "source": [
    "civic_vids_unable_to_normalize = set()\n",
    "\n",
    "with open(\"civic_unable_to_normalize_variation.txt\", \"w+\") as wf:\n",
    "    with open(\"metakb_log_analysis.log\", \"r\") as rf:\n",
    "        wf.write(f\"--------CIViC variants that variation normalizer could not normalize---------\")\n",
    "        for line in rf:\n",
    "            if \"metakb.transform.civic\" in line and \"Variation Normalizer unable to normalize\" in line:\n",
    "                civic_vid = re.findall(r\"civic.vid:\\d+\", line)[0].strip()\n",
    "                all_variant_ids_we_cant_get.add(civic_vid.split(\".vid:\")[-1])\n",
    "                query = line.split(\"using query \")[-1].strip()\n",
    "                civic_vids_unable_to_normalize.add(civic_vid)\n",
    "                wf.write(f\"\\n{civic_vid} : {query}\")\n",
    "\n",
    "print(\"# of CIViC VIDs we can't normalize:\", len(civic_vids_unable_to_normalize))\n",
    "print(\"% of CIViC VIDs we can't normalize:\", len(civic_vids_unable_to_normalize) / total_vids_approved_predictive * 100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of CIViC VIDs that aren't supported: 339\n",
      "% of CIViC VIDs that aren't supported: 35.91101694915254\n"
     ]
    }
   ],
   "source": [
    "civic_vids_not_supported = set()\n",
    "\n",
    "with open(\"civic_does_not_support_variation.txt\", \"w+\") as wf:\n",
    "    with open(\"metakb_log_analysis.log\", \"r\") as rf:\n",
    "        wf.write(f\"--------CIViC variants that are not yet supported---------\")\n",
    "        for line in rf:\n",
    "            if \"metakb.transform.civic\" in line and \"Variation Normalizer does not support\" in line:\n",
    "                civic_vid = re.findall(r\"civic.vid:\\d+\", line)[0].strip()\n",
    "                all_variant_ids_we_cant_get.add(civic_vid.split(\".vid:\")[-1])\n",
    "                query = line.split(\":\")[-1].strip()\n",
    "                civic_vids_not_supported.add(civic_vid)\n",
    "                wf.write(f\"\\n{civic_vid} : {query}\")\n",
    "\n",
    "print(\"# of CIViC VIDs that aren't supported:\", len(civic_vids_not_supported))            \n",
    "print(\"% of CIViC VIDs that aren't supported:\", len(civic_vids_not_supported) / total_vids_approved_predictive * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mutation': 71,\n",
       " 'expression': 67,\n",
       " 'overexpression': 55,\n",
       " 'amplification': 34,\n",
       " 'exon': 23,\n",
       " 'underexpression': 17,\n",
       " 'fusion': 16,\n",
       " 'loss': 15,\n",
       " 'deletion': 12,\n",
       " 'phosphorylation': 5,\n",
       " 'homozygosity': 3,\n",
       " 'frameshift': 3,\n",
       " 'promoter': 3,\n",
       " 'rearrangement': 3,\n",
       " 'levels': 3,\n",
       " 'insertion': 2,\n",
       " 'repeat': 1,\n",
       " 'inactivation': 1,\n",
       " 'mislocalization': 1,\n",
       " 'polymorphism': 1,\n",
       " 'truncation': 1,\n",
       " 'duplication': 1,\n",
       " 'frame': 1,\n",
       " 'shift': 1,\n",
       " 'translocation': 1,\n",
       " 'type': 1,\n",
       " 'wild': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show # of each keyword that are not supported\n",
    "unable_to_normalize = {\n",
    "    \"mutation\", \"amplification\", \"exon\", \"overexpression\",\n",
    "    \"frameshift\", \"promoter\", \"deletion\", \"type\", \"insertion\",\n",
    "    \"expression\", \"duplication\", \"copy\", \"underexpression\",\n",
    "    \"number\", \"variation\", \"repeat\", \"rearrangement\", \"activation\",\n",
    "    \"expression\", \"mislocalization\", \"translocation\", \"wild\",\n",
    "    \"polymorphism\", \"frame\", \"shift\", \"loss\", \"function\", \"levels\",\n",
    "    \"inactivation\", \"snp\", \"fusion\", \"dup\", \"truncation\",\n",
    "    \"homozygosity\", \"gain\", \"phosphorylation\",\n",
    "}\n",
    "unable_to_normalize_counts = dict()\n",
    "with open(\"civic_does_not_support_variation.txt\", \"r\") as rf:\n",
    "    rf.readline()\n",
    "    for vname in rf.readlines():\n",
    "        keys = set(vname.lower().split()) & unable_to_normalize\n",
    "        for k in keys:\n",
    "            if k in unable_to_normalize_counts:\n",
    "                unable_to_normalize_counts[k] += 1\n",
    "            else:\n",
    "                unable_to_normalize_counts[k] = 1\n",
    "unable_to_normalize_counts = dict(sorted(unable_to_normalize_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "unable_to_normalize_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total % of VIDs we can't capture: 59.95762711864406\n"
     ]
    }
   ],
   "source": [
    "print(\"Total % of VIDs we can't capture:\", len(all_variant_ids_we_cant_get) / total_vids_approved_predictive * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of EIDs missed due to Variation Normalizer: 1549\n"
     ]
    }
   ],
   "source": [
    "# See how this affects EIDs\n",
    "eids_missed_due_to_variant = set()\n",
    "variant_id_to_eids_missed = dict()\n",
    "\n",
    "with open(\"metakb_log_analysis.log\", \"r\") as rf:\n",
    "    for line in rf:\n",
    "        if \"has no variation descriptor\" in line:\n",
    "            eid = re.findall(r\"EID\\d+\", line)[0].strip()\n",
    "            eids_missed_due_to_variant.add(eid)\n",
    "            variant_id = line.split(\"variant_id\")[-1].strip()\n",
    "\n",
    "            if variant_id in variant_id_to_eids_missed:\n",
    "                variant_id_to_eids_missed[variant_id].add(eid)\n",
    "            else:\n",
    "                variant_id_to_eids_missed[variant_id] = {eid}\n",
    "\n",
    "variant_id_to_eids_missed = dict(sorted(variant_id_to_eids_missed.items(), key=lambda x: len(x[1]), reverse=True))\n",
    "with open(\"civic_variant_id_to_eids_missed.txt\", \"w+\") as wf:\n",
    "    for k, v in variant_id_to_eids_missed.items():\n",
    "        wf.write(f\"civic.variant:{k} (count of EIDs {len(v)}) : {v}\\n\")\n",
    "            \n",
    "print(f\"# of EIDs missed due to Variation Normalizer:\", len(eids_missed_due_to_variant))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Therapy Normalizer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of CIViC drugs we can't normalize: 54\n",
      "# of EIDs missed due to Therapy Normalizer: 105\n"
     ]
    }
   ],
   "source": [
    "drug_ids_cant_normalize = set()\n",
    "eid_to_drugs = dict()\n",
    "drug_id_to_queries = dict()\n",
    "eids_missed_due_to_therapy = set()\n",
    "drug_id_to_eids_missed = dict()\n",
    "\n",
    "with open(\"metakb_log_analysis.log\", \"r\") as rf:\n",
    "    for line in rf:\n",
    "        if \"Therapy Normalizer unable to normalize\" in line:\n",
    "            drug_id = re.findall(r\"civic.drug:\\d+\", line)[0].strip()\n",
    "            drug_ids_cant_normalize.add(drug_id)\n",
    "\n",
    "            queries = ast.literal_eval(line.split(\"queries \")[-1])\n",
    "            drug_id_to_queries[drug_id] = queries\n",
    "            \n",
    "        elif \"has no therapeutic descriptor\" in line:\n",
    "            eid = re.findall(r\"EID\\d+\", line)[0].strip()\n",
    "            eids_missed_due_to_therapy.add(eid)\n",
    "            drugs = set(ast.literal_eval(line.split(\"drugs: \")[-1]))\n",
    "            for drug_id in drugs:\n",
    "                if drug_id in drug_id_to_eids_missed:\n",
    "                    drug_id_to_eids_missed[drug_id].add(eid)\n",
    "                else:\n",
    "                    drug_id_to_eids_missed[drug_id] = {eid}\n",
    "\n",
    "\n",
    "with open(\"civic_unable_to_normalize_drugs.txt\", \"w+\") as wf:\n",
    "    wf.write(f\"--------Unable to normalize CIViC drug COUNTS (Total drugs: {len(drug_ids_cant_normalize)})---------\")\n",
    "    for drug in drug_ids_cant_normalize:\n",
    "        wf.write(f\"\\n{drug}: {drug_id_to_queries.get(drug)}\")\n",
    "\n",
    "drug_id_to_eids_missed = dict(sorted(drug_id_to_eids_missed.items(), key=lambda x: len(x[1]), reverse=True))\n",
    "with open(\"civic_drug_id_to_eids_missed.txt\", \"w+\") as wf:\n",
    "    for k, v in drug_id_to_eids_missed.items():\n",
    "        wf.write(f\"{k} (count of EIDs {len(v)}) : {v}\\n\")\n",
    "\n",
    "print(f\"# of CIViC drugs we can't normalize: {len(drug_ids_cant_normalize)}\")\n",
    "print(f\"# of EIDs missed due to Therapy Normalizer: {len(eids_missed_due_to_therapy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of EIDs missed due to Therapy Normalizer: 4.23728813559322\n",
      "# of EIDs missed due to Variation Normalizer: 62.51008878127522\n"
     ]
    }
   ],
   "source": [
    "perc_eids_missed_therapy = len(eids_missed_due_to_therapy) / total_approved_predictive_eids * 100\n",
    "perc_eids_missed_variation = len(eids_missed_due_to_variant) / total_approved_predictive_eids * 100\n",
    "print(f\"% of EIDs missed due to Therapy Normalizer: {perc_eids_missed_therapy}\")\n",
    "print(f\"# of EIDs missed due to Variation Normalizer: {perc_eids_missed_variation}\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('metakb-qipIMsDB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "790a71c5f63579f222ae5cd8740ad341e82109efc7b6644c37d71c69f2b3d38e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
