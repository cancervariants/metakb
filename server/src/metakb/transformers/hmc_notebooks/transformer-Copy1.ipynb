{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01de3647-f731-4da0-a12b-ea887e58cb16",
   "metadata": {},
   "source": [
    "##### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4110ccaa-793e-43f0-9d31-00afd6b76c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pprint\n",
    "from urllib.parse import quote_plus\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c12bcf-8cce-4398-be55-bcc103525efb",
   "metadata": {},
   "source": [
    "### DFCI_2014_PES study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e3b6784-eadb-4f80-bf38-d376e31f0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "#TODO import as objects from harvester\n",
    "## add parameter to skip first 4 lines in patient and study sample data\n",
    "\n",
    "init_mut_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_mutations.txt', sep='\\t')\n",
    "init_study_meta = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/meta_study.txt', sep='\\t')\n",
    "init_patient_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_clinical_patient.txt', sep='\\t', skiprows=4)\n",
    "init_sample_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_clinical_sample.txt', sep='\\t', skiprows=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8aeda-91a2-4cf0-9558-cf9292788936",
   "metadata": {},
   "source": [
    "#### Variant data: subset columns, check for duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19a85c8-3894-467e-9c4f-c38549a96f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows : 495\n",
      "\n",
      "Duplicate rows (excluding first instance):\n",
      "      Hugo_Symbol Chromosome  Start_Position  End_Position  \\\n",
      "720         ABCA1          9       107607765     107607765   \n",
      "730         ABCA3         16         2338066       2338066   \n",
      "783         ABCC9         12        21954066      21954066   \n",
      "813         ACACA         17        35640173      35640173   \n",
      "829          ACHE          7       100490251     100490251   \n",
      "...           ...        ...             ...           ...   \n",
      "15134       STAG2          X       123179197     123179197   \n",
      "15155     ZDHHC15          X        74742823      74742824   \n",
      "15191       HUWE1          X        53579734      53579734   \n",
      "15216     SHROOM4          X        50350700      50350700   \n",
      "15218        SOX3          X       139586714     139586714   \n",
      "\n",
      "              Consequence Variant_Classification Variant_Type  \\\n",
      "720      missense_variant      Missense_Mutation          SNP   \n",
      "730      missense_variant      Missense_Mutation          SNP   \n",
      "783      missense_variant      Missense_Mutation          SNP   \n",
      "813      missense_variant      Missense_Mutation          SNP   \n",
      "829    synonymous_variant                 Silent          SNP   \n",
      "...                   ...                    ...          ...   \n",
      "15134         stop_gained      Nonsense_Mutation          SNP   \n",
      "15155  frameshift_variant        Frame_Shift_Ins          INS   \n",
      "15191    missense_variant      Missense_Mutation          SNP   \n",
      "15216    missense_variant      Missense_Mutation          SNP   \n",
      "15218    missense_variant      Missense_Mutation          SNP   \n",
      "\n",
      "      Reference_Allele Tumor_Seq_Allele2   SAMPLE_ID Sequence_Source  \\\n",
      "720                  G                 A  SJDES003-R             WXS   \n",
      "730                  C                 T  SJDES011-R             WXS   \n",
      "783                  C                 T    SJDES017             WXS   \n",
      "813                  T                 C    SJDES005             WXS   \n",
      "829                  G                 A     03-P152             WXS   \n",
      "...                ...               ...         ...             ...   \n",
      "15134                C                 T    SJDES006             WXS   \n",
      "15155                -                 C    SJDES010             WXS   \n",
      "15191                C                 A      TTC466             WXS   \n",
      "15216                C                 T      TTC466             WXS   \n",
      "15218                T                 C      TTC466             WXS   \n",
      "\n",
      "                             HGVSc              HGVSp  HGVSp_Short  \\\n",
      "720     ENST00000374736.3:c.806C>T        p.Ala269Val      p.A269V   \n",
      "730    ENST00000301732.5:c.2965G>A        p.Ala989Thr      p.A989T   \n",
      "783    ENST00000261200.4:c.4562G>A       p.Arg1521Gln     p.R1521Q   \n",
      "813     ENST00000353139.5:c.605A>G        p.Asn202Ser      p.N202S   \n",
      "829    ENST00000302913.4:c.1257C>T          p.Pro419=      p.P419=   \n",
      "...                            ...                ...          ...   \n",
      "15134   ENST00000218089.9:c.646C>T        p.Arg216Ter      p.R216*   \n",
      "15155    ENST00000373367.3:c.36dup  p.Leu13AlafsTer30  p.L13Afs*30   \n",
      "15191  ENST00000342160.3:c.8615G>T       p.Gly2872Val     p.G2872V   \n",
      "15216  ENST00000376020.2:c.3442G>A       p.Glu1148Lys     p.E1148K   \n",
      "15218   ENST00000370536.2:c.512A>G        p.Lys171Arg      p.K171R   \n",
      "\n",
      "         Transcript_ID          RefSeq  Protein_position  \n",
      "720    ENST00000374736     NM_005502.3             269.0  \n",
      "730    ENST00000301732     NM_001089.2             989.0  \n",
      "783    ENST00000261200     NM_020297.2            1521.0  \n",
      "813    ENST00000353139     NM_198834.1             202.0  \n",
      "829    ENST00000302913     NM_015831.2             419.0  \n",
      "...                ...             ...               ...  \n",
      "15134  ENST00000218089  NM_001042749.1             216.0  \n",
      "15155  ENST00000373367     NM_144969.2              12.0  \n",
      "15191  ENST00000342160             NaN            2872.0  \n",
      "15216  ENST00000376020     NM_020717.3            1148.0  \n",
      "15218  ENST00000370536     NM_005634.2             171.0  \n",
      "\n",
      "[495 rows x 17 columns]\n",
      "\n",
      "DataFrame shape after removing duplicates: (14737, 17)\n"
     ]
    }
   ],
   "source": [
    "# clean variant data\n",
    "\n",
    "# subset for necessary columns\n",
    "mut_df = init_mut_df.filter(['Hugo_Symbol',\n",
    "                        'Chromosome',\n",
    "                        'Start_Position', \n",
    "                        'End_Position',\n",
    "                        'Consequence',\n",
    "                        'Variant_Classification',\n",
    "                        'Variant_Type',\n",
    "                        'Reference_Allele',\n",
    "                        'Tumor_Seq_Allele2',\n",
    "                        'Tumor_Sample_Barcode',\n",
    "                        'Sequence_Source',\n",
    "                        'HGVSc',\n",
    "                        'HGVSp',\n",
    "                        'HGVSp_Short',\n",
    "                        'Transcript_ID',\n",
    "                        'RefSeq',\n",
    "                        'Protein_position'\n",
    "                       ], axis=1)\n",
    "\n",
    "\n",
    "# Strip whitespace and retry\n",
    "mut_df.columns = mut_df.columns.str.strip()\n",
    "mut_df = mut_df.rename(columns={'Tumor_Sample_Barcode': 'SAMPLE_ID'})\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = mut_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# TODO check duplicates for sanity check\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(mut_df[mut_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# save duplicate rows to file\n",
    "    dupes = mut_df[mut_df.duplicated(keep=False)]\n",
    "    mut_df.to_csv('mut_dupes.csv', index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "# remove duplicates, but keep first occurrence\n",
    "    mut_df = mut_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {mut_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "\n",
    "    \n",
    "# print(mut_df.columns)\n",
    "# # print(mut_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f5ee3-c672-4e26-b670-576086526f13",
   "metadata": {},
   "source": [
    "#### Patient data: subset columns, check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f3d6c8-9257-4ac6-b883-75a967ba8592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT_ID', 'AGE', 'SEX', 'ETHNICITY'], dtype='object')\n",
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# clean patient data\n",
    "# print(patient_df.shape)\n",
    "# print(patient_df.columns)\n",
    "\n",
    "# subset data\n",
    "# subset for necessary columns\n",
    "patient_df = init_patient_df.filter(['PATIENT_ID',\n",
    "                        'AGE',\n",
    "                        'SEX', \n",
    "                        'ETHNICITY',\n",
    "                        'Consequence'\n",
    "                       ], axis=1)\n",
    "\n",
    "print(patient_df.columns)\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = patient_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(patient_df[patient_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    patient_df = patient_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {patient_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da33e63-f38d-4d9e-abdc-e3c0bba84675",
   "metadata": {},
   "source": [
    "#### Sample data: subset columns, check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb2499e2-affb-404e-b970-04aa20bef06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT_ID', 'SAMPLE_ID', 'SAMPLE_CLASS', 'ONCOTREE_CODE',\n",
      "       'CANCER_TYPE', 'CANCER_TYPE_DETAILED', 'TMB_NONSYNONYMOUS'],\n",
      "      dtype='object')\n",
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# clean sample data\n",
    "\n",
    "# print(sample_df.shape)\n",
    "# print(sample_df.columns)\n",
    "# print(sample_df.head())\n",
    "\n",
    "\n",
    "# subset data\n",
    "# subset for necessary columns\n",
    "sample_df = init_sample_df.filter(['PATIENT_ID',\n",
    "                                     'SAMPLE_ID',\n",
    "                                     'SAMPLE_CLASS',\n",
    "                                     'ONCOTREE_CODE',\n",
    "                                     'CANCER_TYPE',\n",
    "                                     'CANCER_TYPE_DETAILED',\n",
    "                                     'TMB_NONSYNONYMOUS'\n",
    "                                    ], axis=1)\n",
    "\n",
    "\n",
    "print(sample_df.columns)\n",
    "\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = sample_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(sample_df[sample_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    sample_df = sample_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {sample_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671c4ad-d0b6-43e1-b15c-ec749665175d",
   "metadata": {},
   "source": [
    "#### Combine dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4cd556-6160-44dd-9c56-f7f27a387f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataframes\n",
    "## TODO: redo so that all columns are available and that records with no samples will be there. \"left outer join\"? will get NAs.\n",
    "\n",
    "init_combined_df = mut_df.merge(sample_df, on='SAMPLE_ID', how='left')\n",
    "\n",
    "# print(mut_df.columns)\n",
    "# print(mut_df.shape)\n",
    "\n",
    "# print(sample_df.columns)\n",
    "# print(sample_df.shape)\n",
    "\n",
    "# print(init_combined_df.columns)\n",
    "# print(init_combined_df.shape)\n",
    "\n",
    "#add patient_df\n",
    "combined_df = init_combined_df.merge(patient_df, on='PATIENT_ID', how='left')\n",
    "\n",
    "# print(patient_df.columns)\n",
    "# print(patient_df.shape)\n",
    "\n",
    "# print(combined_df.columns)\n",
    "# print(combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970da22-8dc7-4cc4-aa62-9becb291bbeb",
   "metadata": {},
   "source": [
    "#### Add STUDY_ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c2fd3ee-02fc-48bf-acc9-7675137eea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add column for study id\n",
    "study_id = init_study_meta.iloc[0, 0]\n",
    "study_id = study_id.replace('cancer_study_identifier: ', '')\n",
    "# study_id\n",
    "combined_df['STUDY_ID'] = study_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90899975-c174-43d5-a7ae-2369d22f35f6",
   "metadata": {},
   "source": [
    "#### Check for (and remove) duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aee6b500-7a61-4190-934b-53c7055686b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = combined_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(combined_df[combined_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {combined_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59990c-e8c3-41bd-ab79-4c0e505e1e72",
   "metadata": {},
   "source": [
    "#### Remove data from cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0bcca1-476e-4e77-a0a1-bb3a3bab9b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (14737, 27)\n",
      "Removed 3123 rows where SAMPLE_CLASS == 'Cell line'\n",
      "New shape: (11614, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SAMPLE_CLASS\n",
       "Cell line    3123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# remove cell lines\n",
    "\n",
    "original_shape = combined_df.shape\n",
    "print(f\"Original shape: {original_shape}\")\n",
    "\n",
    "#lines to remove\n",
    "removed_df = combined_df[combined_df['SAMPLE_CLASS'] == 'Cell line']\n",
    "\n",
    "# remove cell lines\n",
    "filtered_df = combined_df[combined_df['SAMPLE_CLASS'] != 'Cell line']\n",
    "\n",
    "# calculate how many rows were removed\n",
    "rows_removed = original_shape[0] - filtered_df.shape[0]\n",
    "print(f\"Removed {rows_removed} rows where SAMPLE_CLASS == 'Cell line'\")\n",
    "\n",
    "# print new shape\n",
    "print(f\"New shape: {filtered_df.shape}\")\n",
    "\n",
    "# reassign df\n",
    "combined_df = filtered_df\n",
    "\n",
    "removed_df.to_csv('cell_lines_removed.csv', index=False)\n",
    "removed_df.value_counts(\"SAMPLE_CLASS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b299dc-a8b9-4036-8431-7e336ea69170",
   "metadata": {},
   "source": [
    "#### Write value counts for NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f130c2-8fd1-481b-8f5a-00db0ded9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Value counts written for 27 columns to folder: value_counts_by_column\n"
     ]
    }
   ],
   "source": [
    "# combined_df.isna().sum()\n",
    "\n",
    "# Hugo_Symbol                   0\n",
    "# Chromosome                    0\n",
    "# Start_Position                0\n",
    "# End_Position                  0\n",
    "# Consequence                 124 - some of the Variant_Classification=Silent have no consequence described\n",
    "# Variant_Classification        0\n",
    "# Variant_Type                  0\n",
    "# Reference_Allele              0\n",
    "# Tumor_Seq_Allele2             0\n",
    "# SAMPLE_ID                     0\n",
    "# Sequence_Source               0\n",
    "# HGVSc                       136 - some of the Variant_Classification=Silent and all of the Variant_Classification=3'Flank and 5'Flank\n",
    "# HGVSp                       346 \n",
    "# Transcript_ID               124 - some of the Variant_Classification=Silent have no Transcript_ID described\n",
    "# RefSeq                     1338\n",
    "# Protein_position            334\n",
    "# Gnomad_Notation               0\n",
    "# PATIENT_ID                    0\n",
    "# SAMPLE_CLASS                  0\n",
    "# ONCOTREE_CODE                 0\n",
    "# CANCER_TYPE                   0\n",
    "# CANCER_TYPE_DETAILED          0\n",
    "# TMB_NONSYNONYMOUS             0\n",
    "# AGE                        4745 - some ages undisclosed\n",
    "# SEX                           0\n",
    "# ETHNICITY                 10900 - many patients' ethnicities undisclosed\n",
    "# STUDY_ID                      0\n",
    "\n",
    "\n",
    "# define output folder (will create it if needed)\n",
    "output_dir = \"value_counts_by_column\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# loop through each column\n",
    "for col in combined_df.columns:\n",
    "    # build filename\n",
    "    filename = f\"value_counts_{col}.txt\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # write counts to file\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(f\"Value counts for column: {col}\\n\\n\")\n",
    "        f.write(combined_df[col].value_counts(dropna=False).to_string())\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"✅ Value counts written for {len(combined_df.columns)} columns to folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f92414-9951-4286-a145-adcc3dab3675",
   "metadata": {},
   "source": [
    "#### Replace missing patient, sample data with \"No_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b032d44-fcdd-45c1-b4cb-6d42c6b23894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hugo_Symbol                  0\n",
       "Chromosome                   0\n",
       "Start_Position               0\n",
       "End_Position                 0\n",
       "Consequence                  0\n",
       "Variant_Classification       0\n",
       "Variant_Type                 0\n",
       "Reference_Allele             0\n",
       "Tumor_Seq_Allele2            0\n",
       "SAMPLE_ID                    0\n",
       "Sequence_Source              0\n",
       "HGVSc                      136\n",
       "HGVSp                      346\n",
       "HGVSp_Short                136\n",
       "Transcript_ID              124\n",
       "RefSeq                    1338\n",
       "Protein_position           334\n",
       "PATIENT_ID                   0\n",
       "SAMPLE_CLASS                 0\n",
       "ONCOTREE_CODE                0\n",
       "CANCER_TYPE                  0\n",
       "CANCER_TYPE_DETAILED         0\n",
       "TMB_NONSYNONYMOUS            0\n",
       "AGE                          0\n",
       "SEX                          0\n",
       "ETHNICITY                    0\n",
       "STUDY_ID                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filling in NaNs - AGE, ETHNICITY, Consequence\n",
    "# TODO add consequence with annotation\n",
    "\n",
    "cols_to_fill = ['Consequence', 'AGE', 'ETHNICITY']\n",
    "fill_value = \"No_Data\"\n",
    "\n",
    "for col in cols_to_fill:\n",
    "    combined_df[col] = combined_df[col].fillna(fill_value)\n",
    "\n",
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae16729-f4ba-44bf-bdbe-b312b46a8482",
   "metadata": {},
   "source": [
    "#### Construct GnomAD variant ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e34f131-d3b7-452c-9c3e-39f79b3157d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct Gnomad variant ID column\n",
    "combined_df[\"temp_Gnomad_Notation\"] = combined_df.apply(\n",
    "    lambda row: f\"{row['Chromosome']}-{row['Start_Position']}-{row['Reference_Allele']}-{row['Tumor_Seq_Allele2']}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c762e-4548-439c-ba88-ec9dbfc049a5",
   "metadata": {},
   "source": [
    "#### Correcting Chromosome 23 samples to X or Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25862726-3cf2-41fc-91a6-ed9a0e6f9038",
   "metadata": {},
   "source": [
    "##### Write initial combined_df to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a83e5e-5984-4c3c-9d66-a87e7ebe31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('output0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f5960-4dfe-425e-8afb-64fc973af53c",
   "metadata": {},
   "source": [
    "##### Set test variables and REST API variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d4679e-bbff-4262-aa50-4c2cdfa574b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://normalize.cancervariants.org/variation/\"\n",
    "# HEADERS = {\"Accept\": \"application/json\"}\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"  # mimics a browser\n",
    "}\n",
    "# variant = \"23-2408485-G-C\"\n",
    "# gene = \"ZBED1\"\n",
    "\n",
    "PATTERN = re.compile(r'^23-')        # anchored ^ so only the chromosome prefix is substituted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674efbf-645c-4fb0-8b5d-89aa0092ff16",
   "metadata": {},
   "source": [
    "##### FUNCTION: Flag rows with Chrom23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae6af5f6-df95-407e-843b-5e500174b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_rows_chrom_23(df):\n",
    "    \"\"\"\n",
    "    Create \"Chrom_23\" column, True for those with Chromosome = 23\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain column 'Chromosome'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    df[\"Chrom_23\"] = False\n",
    "    # print(combined_df.head)\n",
    "    df[\"Chrom_23\"] = df[\"Chromosome\"].astype(str).str.strip().eq(\"23\")\n",
    "    df.loc[df[\"Chromosome\"] == 23, \"Chrom_23\"] = True\n",
    "    # print(combined_df[\"Chrom_23\"].value_counts())\n",
    "    # print(combined_df[\"Chromosome\"].value_counts())\n",
    "    return df\n",
    "\n",
    "combined_df = flag_rows_chrom_23(combined_df)\n",
    "\n",
    "combined_df.to_csv(\"output_flag_chrom_23.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcedfb9-01e0-4b35-8b47-d174acc8913d",
   "metadata": {},
   "source": [
    "##### FUNCTION: change female chrom23 to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8d93f16-6243-4659-a0f9-2dda39f41c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(combined_df[\"Chromosome\"].value_counts())\n",
    "\n",
    "def chr23_female(df):\n",
    "    \"\"\"\n",
    "    Convert Chromosome 23 to 'X' for rows where SEX is female.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns 'Chromosome' and 'SEX'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    # Ensure we’re comparing like with like\n",
    "    chr_col = df[\"Chromosome\"].astype(str).str.strip()\n",
    "    sex_col = df[\"SEX\"].astype(str).str.upper().str.strip()   # handles 'F', 'f', 'Female', etc.\n",
    "    \n",
    "    mask = (chr_col == \"23\") & (sex_col.str.startswith(\"F\"))\n",
    "    df.loc[mask, \"Chromosome\"] = \"X\"\n",
    "    return df\n",
    "\n",
    "combined_df = chr23_female(combined_df)\n",
    "\n",
    "# print(combined_df[\"Chromosome\"].value_counts())\n",
    "\n",
    "combined_df.to_csv('output1_femaleX.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2561146-6f6b-42ab-80c1-02b741f144a6",
   "metadata": {},
   "source": [
    "##### FUNCTION: Add cols for Chr23_X and Chr23_Y, fill with false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1af4f568-4f1b-49db-b467-c96601462b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cols_chrom_23_male(df):\n",
    "    \"\"\"\n",
    "    Create \"Chr23_X and Chr23_Y\" columns, fill with false\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain column 'Chromosome'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    df[\"Chr23_X\"] = False\n",
    "    df[\"Chr23_Y\"] = False\n",
    "    # df[\"Chrom_23\"] = df[\"Chromosome\"].astype(str).str.strip().eq(\"23\")\n",
    "    # df.loc[df[\"Chromosome\"] == 23, \"Chrom_23\"] = True\n",
    "    # print(combined_df[\"Chr23_X\"].value_counts())\n",
    "    # print(combined_df[\"Chr23_Y\"].value_counts())\n",
    "    return df\n",
    "\n",
    "# combined_df = add_cols_chrom_23_male(combined_df)\n",
    "\n",
    "# combined_df.to_csv('output2_new_chr23_boolean_cols.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58318277-4ba6-4507-830f-799f37ee44b7",
   "metadata": {},
   "source": [
    "##### Setting chromosome 23 variant notations as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c3ea76d-160f-4929-bfed-0ebfada5703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-129273827-C-T\n"
     ]
    }
   ],
   "source": [
    "# chrom_23_list = combined_df.loc[\n",
    "#     combined_df[\"temp_Gnomad_Notation\"].str.startswith(\"23-\", na=False),\n",
    "#     \"temp_Gnomad_Notation\"\n",
    "# ].tolist()\n",
    "\n",
    "# with open(\"chrom_23_list.json\", \"w\") as f:\n",
    "#     json.dump(chrom_23_list, f, indent=2)\n",
    "\n",
    "# variant = chrom_23_list\n",
    "\n",
    "# print(chrom_23_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b658bce-5d6f-4425-adae-c558405b5cd4",
   "metadata": {},
   "source": [
    "##### FUNCTION: Adjust GnomAD variant to accept X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45a3f2f9-eb2f-436d-afb9-ba34549ab844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chr23_to_X(variant: list[str]) -> list[str]:\n",
    "    \"\"\"Convert any '23-' prefix in a list of variants to 'X-'.\"\"\"\n",
    "    return [PATTERN.sub('X-', v) if isinstance(v, str) else v for v in variant]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3684d2-171a-4bec-a7e5-7e31fb981843",
   "metadata": {},
   "source": [
    "##### FUNCTION: Adjust GnomAD variant to accept Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3131ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chr23_to_Y(variant: list[str]) -> list[str]:\n",
    "    \"\"\"Convert any '23-' prefix in a list of variants to 'X-'.\"\"\"\n",
    "    return [PATTERN.sub('Y-', v) if isinstance(v, str) else v for v in variant]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff163d-467b-45f6-8fd8-f60c712b3218",
   "metadata": {},
   "source": [
    "##### FUNCTION: Test tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab550938-ef32-4523-ae65-503c3237f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_tokenization(variant):\n",
    "#     \"\"\"Fetch gene from VICC variation normalizer\"\"\"\n",
    "#     url = f\"{BASE_URL}normalize?q={variant}\"\n",
    "#     response = requests.get(url, headers=HEADERS)\n",
    "#     if response.status_code == 200:\n",
    "#         return response.json()\n",
    "#     else:\n",
    "#         print(f\"Error {response.status_code}: {response.text}\")\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "142f88ad-2807-404b-8320-1d1ef8b367d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # --- Query and collect results ---\n",
    "# results = []\n",
    "\n",
    "# for variant in variant:\n",
    "#     try:\n",
    "#         url = f\"{BASE_URL}?q={variant}&assembly=GRCh37\"\n",
    "#         response = requests.get(url, headers=HEADERS)\n",
    "#         if response.status_code == 200:\n",
    "#             data = response.json()\n",
    "#             results.append({\n",
    "#                 \"original_variant\": variant,\n",
    "#                 \"response\": json.dumps(data)  # store raw JSON as string\n",
    "#             })\n",
    "#         else:\n",
    "#             results.append({\n",
    "#                 \"original_variant\": variant,\n",
    "#                 \"response\": f\"Error {response.status_code}: {response.text}\"\n",
    "#             })\n",
    "#     except Exception as e:\n",
    "#         results.append({\n",
    "#             \"original_variant\": variant,\n",
    "#             \"response\": f\"Exception: {str(e)}\"\n",
    "#         })\n",
    "    \n",
    "#     time.sleep(0.5)  # polite rate-limiting\n",
    "\n",
    "# # --- Save to CSV ---\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv(\"normalized_variants_output.csv\", index=False)\n",
    "# print(\"Saved results to normalized_variants_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21497eb6-533b-4e1d-a205-0eb32d868be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_tokenization(variant, output_csv=\"normalized_variants_output.csv\", delay=0.5):\n",
    "    \"\"\"\n",
    "    Fetch normalized variant info from VICC API for each variant in list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    variant_list : list of str\n",
    "        List of GnomAD-style variants (e.g., '23-2408485-G-C').\n",
    "    output_csv : str\n",
    "        Filename for the output CSV.\n",
    "    delay : float\n",
    "        Seconds to wait between API requests (default 0.5).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with original variant and raw JSON string response.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for v in variant:\n",
    "        url = f\"{BASE_URL}normalize?q={v}\"\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=HEADERS)\n",
    "            # if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            results.append({\n",
    "                \"variant\": v,\n",
    "                \"response\": json.dumps(data)  # store raw JSON as string\n",
    "            })\n",
    "                \n",
    "            # else:\n",
    "            #     results.append({\n",
    "            #         \"variant\": v,\n",
    "            #         \"response\": f\"Error {response.status_code}: {response.text}\"\n",
    "            #     })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"variant\": v,\n",
    "                \"response\": f\"Exception: {str(e)}\"\n",
    "            })\n",
    "        \n",
    "        time.sleep(delay)\n",
    "\n",
    "    # return results\n",
    "    print(type(results))\n",
    "\n",
    "#     if response.status_code == 200:\n",
    "#         return response.json()\n",
    "#     else:\n",
    "#         print(f\"Error {response.status_code}: {response.text}\")\n",
    "#         return None\n",
    "\n",
    "    API_response_df = pd.DataFrame(results)\n",
    "    API_response_df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Saved {len(results)} results to {output_csv}\")\n",
    "    return results\n",
    "    # return API_response_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447f008-e20c-4328-b44c-fd4c7589dabc",
   "metadata": {},
   "source": [
    "##### FUNCTION: Check if variant on X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb88a037-a608-45e5-91a2-1a71327e1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_x_variant(df, variant):\n",
    "    variant_x = chr23_to_X(variant)\n",
    "    x_r       = test_tokenization(variant_x)\n",
    "\n",
    "    # if \"variation\" not in x_r:\n",
    "    #     return df\n",
    "\n",
    "    if x_r is None or \"variation\" not in x_r:   # <- ✅ Add `x_r is None` check here\n",
    "        return df\n",
    "\n",
    "    x_symbols = [\n",
    "        gene[\"symbol\"]\n",
    "        for ext in x_r[\"variation\"].get(\"extensions\", [])\n",
    "        if ext.get(\"name\") == \"mane_genes\"\n",
    "        for gene in ext.get(\"value\", [])\n",
    "        if \"symbol\" in gene\n",
    "    ]\n",
    "\n",
    "    if x_symbols:\n",
    "        if \"Chr23_X\" not in df.columns:\n",
    "            df[\"Chr23_X\"] = False\n",
    "        df.loc[df[\"Hugo_Symbol\"].isin(x_symbols), \"Chr23_X\"] = True\n",
    "        print(\"X symbols:\", x_symbols)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90011ef4-8467-47e8-86a8-9e4c4f0b99c5",
   "metadata": {},
   "source": [
    "##### FUNCTION: Check if variant on Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ce24b9c-aa33-4fef-a96c-43e168ddc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_y_variant(df, variant):\n",
    "    variant_y = chr23_to_Y(variant)\n",
    "    y_r       = test_tokenization(variant_y)\n",
    "\n",
    "    # if \"variation\" not in y_r:          # guard against 422 / 404 replies\n",
    "    #     return df\n",
    "\n",
    "    if y_r is None or \"variation\" not in y_r:   # <- ✅ Add `y_r is None` check here\n",
    "        return df\n",
    "\n",
    "    y_symbols = [\n",
    "        gene[\"symbol\"]\n",
    "        for ext in y_r[\"variation\"].get(\"extensions\", [])\n",
    "        if ext.get(\"name\") == \"mane_genes\"\n",
    "        for gene in ext.get(\"value\", [])\n",
    "        if \"symbol\" in gene\n",
    "    ]\n",
    "\n",
    "    if y_symbols:\n",
    "        if \"Chr23_Y\" not in df.columns:\n",
    "            df[\"Chr23_Y\"] = False\n",
    "        df.loc[df[\"Hugo_Symbol\"].isin(y_symbols), \"Chr23_Y\"] = True\n",
    "        print(\"Y symbols:\", y_symbols)\n",
    "\n",
    "    print(variant_y)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18252a87-c901-46f8-9b13-715d20f32099",
   "metadata": {},
   "source": [
    "##### FUNCTION: Master function for dealing with male chrom23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a18fa41-7ef2-49a9-a4f4-ffb183fb881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chr23_male(df, variant):\n",
    "    df = add_cols_chrom_23_male(df)          # prep chromosome-23 columns\n",
    "\n",
    "    df = check_for_x_variant(df, variant)    # pass **both** args\n",
    "    df = check_for_y_variant(df, variant)\n",
    "\n",
    "    df.to_csv(\"output2_new_chr23_boolean_cols.csv\", index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86247e94-f6e5-4036-b60f-77f9ea327693",
   "metadata": {},
   "source": [
    "##### RUN: driver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "91705e89-0bb1-43e4-acfb-e65ee791c519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "✅ Saved 124 results to normalized_variants_output.csv\n",
      "<class 'list'>\n",
      "✅ Saved 124 results to normalized_variants_output.csv\n",
      "Chr23_X\n",
      "False    11614\n",
      "Name: count, dtype: int64\n",
      "Chr23_Y\n",
      "False    11614\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "result_df = chr23_male(combined_df, variant)\n",
    "\n",
    "print(result_df[\"Chr23_X\"].value_counts(dropna=False))\n",
    "print(result_df[\"Chr23_Y\"].value_counts(dropna=False))\n",
    "\n",
    "result_df.to_csv(\"output_post_23_BOOLEAN.csv\", index=False)\n",
    "\n",
    "#tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9573318-5a06-4f42-a58a-9bc1a6f56ef9",
   "metadata": {},
   "source": [
    "##### FUNCTION: Reassign male chrom 23s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de80033f-138b-4cd3-ba04-ce074cc61768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_male_chrom23(df):\n",
    "    # Initialize ambig_chrom with a default value\n",
    "    df[\"ambig_chrom\"] = \"non-ambiguous\"\n",
    "\n",
    "    # Limit all logic to Chromosome 23 rows\n",
    "    chr23_mask = df[\"Chromosome\"] == 23\n",
    "\n",
    "    # X-only: Chr23_X == True, Chr23_Y == False\n",
    "    mask_x = chr23_mask & (df[\"Chr23_X\"] == True) & (df[\"Chr23_Y\"] == False)\n",
    "    df.loc[mask_x, \"Chromosome\"] = \"X\"\n",
    "\n",
    "    # Y-only: Chr23_Y == True, Chr23_X == False\n",
    "    mask_y = chr23_mask & (df[\"Chr23_Y\"] == True) & (df[\"Chr23_X\"] == False)\n",
    "    df.loc[mask_y, \"Chromosome\"] = \"Y\"\n",
    "\n",
    "    # Both X and Y → ambiguous\n",
    "    mask_xy = chr23_mask & (df[\"Chr23_X\"] == True) & (df[\"Chr23_Y\"] == True)\n",
    "    df.loc[mask_xy, \"ambig_chrom\"] = \"XY\"\n",
    "\n",
    "    # Neither X nor Y → ambiguous\n",
    "    mask_neither = chr23_mask & (df[\"Chr23_X\"] == False) & (df[\"Chr23_Y\"] == False)\n",
    "    df.loc[mask_neither, \"ambig_chrom\"] = \"neither\"\n",
    "\n",
    "    # Reconfirm and correct values where ambig_chrom is non-ambiguous\n",
    "    nonambig_mask = chr23_mask & (df[\"ambig_chrom\"] == \"non-ambiguous\")\n",
    "    df.loc[nonambig_mask & (df[\"Chr23_X\"] == True), \"Chromosome\"] = \"X\"\n",
    "    df.loc[nonambig_mask & (df[\"Chr23_Y\"] == True), \"Chromosome\"] = \"Y\"\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09cbb2-bd23-4424-87f4-05cb9f21ae61",
   "metadata": {},
   "source": [
    "##### RUN: Correct male 23s and see if any ambiguous chromosome 23 values exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dbe5829-d125-46b7-9a56-4411b305aec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambig_chrom\n",
      "non-ambiguous    11614\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "correct_male_chrom23(result_df)\n",
    "\n",
    "print(result_df[\"ambig_chrom\"].value_counts())\n",
    "\n",
    "result_df.to_csv(\"output_post_23_correction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a190ae-bf47-45bc-814e-b4c3ec41875c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc34dd19-40d4-4505-9775-f35062b52820",
   "metadata": {},
   "source": [
    "##### Next step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ee2f0126-563b-424e-b26e-f27d3a909d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make \"variables\" a list from the df where chrom=23 and sex=M\n",
    "\n",
    "\n",
    "#check for ambiguous chromosomes\n",
    "# if none, create Gnomad column and write gnomad notations in it.\n",
    "#delete temp gnomad column\n",
    "\n",
    "#If there are ambiguous chromosomes, stop analysis\n",
    "#if XY or None, stop to look through manually\n",
    "\n",
    "# check gene symbols against each other\n",
    "#write df\n",
    "\n",
    "#remove temporary columns\n",
    "\n",
    "#get missing p dots!\n",
    "\n",
    "#consolidate driver function\n",
    "\n",
    "#Need function that tkes gnomad notation and puts it through normalizer, then takes response and fashions it into the test fixture\n",
    "#put response into columns \"focus variant members\", etc. \n",
    "\n",
    "#figure out other info for object - cohort, frequency, etc. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d56ef311",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['Gnomad_Notation'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n7/jxfygfkj2w182jgqtmnmzl7r0000gq/T/ipykernel_89440/3686122230.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# remove variant dupes per patient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# find duplicated (PATIENT_ID, Gnomad_Notation) pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdupe_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PATIENT_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Gnomad_Notation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"first\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# new DataFrame with the duplicated rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpatient_variant_dupes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdupe_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# remove those rows from the original DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/metakb/venv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6946\u001b[0m         \u001b[0;31m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6947\u001b[0m         \u001b[0;31m# key that doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6948\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6950\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6953\u001b[0m             \u001b[0;31m# GH#45236 This is faster than get_group_index below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Index(['Gnomad_Notation'], dtype='object')"
     ]
    }
   ],
   "source": [
    "# remove variant dupes per patient\n",
    "\n",
    "# find duplicated (PATIENT_ID, Gnomad_Notation) pairs\n",
    "dupe_mask = combined_df.duplicated(subset=[\"PATIENT_ID\", \"Gnomad_Notation\"], keep=\"first\")\n",
    "# new DataFrame with the duplicated rows\n",
    "patient_variant_dupes = combined_df[dupe_mask]\n",
    "# remove those rows from the original DataFrame\n",
    "combined_df_cleaned = combined_df[~dupe_mask]\n",
    "# write removed rows to file\n",
    "patient_variant_dupes.to_csv(\"patient_variant_dupes.csv\", index=False)\n",
    "# print the number of rows removed\n",
    "print(f\"Removed {patient_variant_dupes.shape[0]} rows with duplicated Gnomad_Notation per PATIENT_ID.\")\n",
    "# reassign dataframe:\n",
    "combined_df = combined_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a1e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5738f-f282-4550-9c76-d1b3c82f3880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
