{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e47f65-5fc7-4e66-9863-a7d32d01e2ea",
   "metadata": {},
   "source": [
    "### DFCI_2014_PES study upload and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d73e57cb-4672-4388-a5bb-490f69d87515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f678c987-3fc8-47c5-b061-48072805751a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Downloaded es_dfarber_broad_2014.tar.gz\n",
      "Extracted to: es_dfarber_broad_2014_extracted\n",
      "(15232, 45)\n",
      "Index(['Hugo_Symbol', 'Entrez_Gene_Id', 'Center', 'NCBI_Build', 'Chromosome',\n",
      "       'Start_Position', 'End_Position', 'Strand', 'Consequence',\n",
      "       'Variant_Classification', 'Variant_Type', 'Reference_Allele',\n",
      "       'Tumor_Seq_Allele1', 'Tumor_Seq_Allele2', 'dbSNP_RS',\n",
      "       'dbSNP_Val_Status', 'Tumor_Sample_Barcode',\n",
      "       'Matched_Norm_Sample_Barcode', 'Match_Norm_Seq_Allele1',\n",
      "       'Match_Norm_Seq_Allele2', 'Tumor_Validation_Allele1',\n",
      "       'Tumor_Validation_Allele2', 'Match_Norm_Validation_Allele1',\n",
      "       'Match_Norm_Validation_Allele2', 'Verification_Status',\n",
      "       'Validation_Status', 'Mutation_Status', 'Sequencing_Phase',\n",
      "       'Sequence_Source', 'Validation_Method', 'Score', 'BAM_File',\n",
      "       'Sequencer', 't_ref_count', 't_alt_count', 'n_ref_count', 'n_alt_count',\n",
      "       'HGVSc', 'HGVSp', 'HGVSp_Short', 'Transcript_ID', 'RefSeq',\n",
      "       'Protein_position', 'Codons', 'Hotspot'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# upload mutations data\n",
    "\n",
    "# df = pd.read_csv('/Users/costellh/meta_kb/pediatric_data/DFCI_2014_PES/es_dfarber_broad_2014/data_mutations.txt', sep='\\t')\n",
    "url = \"https://cbioportal-datahub.s3.amazonaws.com/es_dfarber_broad_2014.tar.gz\"\n",
    "output_path = \"es_dfarber_broad_2014.tar.gz\"\n",
    "query_parameters = {\"downloadformat\": \"tar.gz\"}\n",
    "\n",
    "response = requests.get(url, stream=True, params=query_parameters)\n",
    "print(response.status_code)\n",
    "\n",
    "with open (\"es_dfarber_broad_2014.tar.gz\", mode=\"wb\") as file: \n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        file.write(chunk)\n",
    "    print(f\"Downloaded {output_path}\")\n",
    "\n",
    "\n",
    "extract_dir = \"es_dfarber_broad_2014_extracted\"\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "with tarfile.open(output_path, mode=\"r:gz\") as tar:\n",
    "    tar.extractall(path=extract_dir)\n",
    "\n",
    "print(f\"Extracted to: {extract_dir}\")\n",
    "\n",
    "#TODO: softcode this\n",
    "df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_mutations.txt', sep='\\t')\n",
    "print(df.shape)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4429287-5700-4f8d-8b0d-c477463fef50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15232, 26)\n",
      "Index(['Hugo_Symbol', 'Entrez_Gene_Id', 'Center', 'NCBI_Build', 'Chromosome',\n",
      "       'Start_Position', 'End_Position', 'Strand', 'Consequence',\n",
      "       'Variant_Classification', 'Variant_Type', 'Reference_Allele',\n",
      "       'Tumor_Seq_Allele1', 'Tumor_Seq_Allele2', 'dbSNP_RS',\n",
      "       'Tumor_Sample_Barcode', 'Sequence_Source', 'Sequencer', 'HGVSc',\n",
      "       'HGVSp', 'HGVSp_Short', 'Transcript_ID', 'RefSeq', 'Protein_position',\n",
      "       'Codons', 'Hotspot'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# remove empty and unnecessary columns\n",
    "\n",
    "emp_col = df.isnull().all()\n",
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "# # Create a dataframe with columns A,B,C and D\n",
    "# df = pd.DataFrame(np.random.randn(100, 4), columns=list('ABCD'))\n",
    "\n",
    "# # Try to create a second dataframe df2 from df with all columns except 'B' and D\n",
    "# my_cols = set(df.columns)\n",
    "# my_cols.remove('B').remove('D')\n",
    "\n",
    "# # This returns an error (\"unhashable type: set\")\n",
    "# df2 = df[my_cols]\n",
    "\n",
    "# subset for necessary columns\n",
    "subset_df = old.filter(['Hugo_Symbol',\n",
    "                        'Chromosome',\n",
    "                        'Start_position', \n",
    "                        'End_Position',\n",
    "                        '                       \n",
    "                       ], axis=1)\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40424301-dc86-4086-b012-1a04b0e48d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Gnomad variant expression column\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
