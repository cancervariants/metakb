{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a47b6a03-4a0f-480f-bb9a-cc2dc0d33f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pprint\n",
    "from urllib.parse import quote_plus  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c12bcf-8cce-4398-be55-bcc103525efb",
   "metadata": {},
   "source": [
    "### DFCI_2014_PES study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3b6784-eadb-4f80-bf38-d376e31f0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "#TODO import as objects from harvester\n",
    "## add parameter to skip first 4 lines in patient and study sample data\n",
    "\n",
    "init_mut_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_mutations.txt', sep='\\t')\n",
    "init_study_meta = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/meta_study.txt', sep='\\t')\n",
    "init_patient_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_clinical_patient.txt', sep='\\t', skiprows=4)\n",
    "init_sample_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_clinical_sample.txt', sep='\\t', skiprows=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b19a85c8-3894-467e-9c4f-c38549a96f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows : 495\n",
      "\n",
      "Duplicate rows (excluding first instance):\n",
      "      Hugo_Symbol Chromosome  Start_Position  End_Position  \\\n",
      "720         ABCA1          9       107607765     107607765   \n",
      "730         ABCA3         16         2338066       2338066   \n",
      "783         ABCC9         12        21954066      21954066   \n",
      "813         ACACA         17        35640173      35640173   \n",
      "829          ACHE          7       100490251     100490251   \n",
      "...           ...        ...             ...           ...   \n",
      "15134       STAG2          X       123179197     123179197   \n",
      "15155     ZDHHC15          X        74742823      74742824   \n",
      "15191       HUWE1          X        53579734      53579734   \n",
      "15216     SHROOM4          X        50350700      50350700   \n",
      "15218        SOX3          X       139586714     139586714   \n",
      "\n",
      "              Consequence Variant_Classification Variant_Type  \\\n",
      "720      missense_variant      Missense_Mutation          SNP   \n",
      "730      missense_variant      Missense_Mutation          SNP   \n",
      "783      missense_variant      Missense_Mutation          SNP   \n",
      "813      missense_variant      Missense_Mutation          SNP   \n",
      "829    synonymous_variant                 Silent          SNP   \n",
      "...                   ...                    ...          ...   \n",
      "15134         stop_gained      Nonsense_Mutation          SNP   \n",
      "15155  frameshift_variant        Frame_Shift_Ins          INS   \n",
      "15191    missense_variant      Missense_Mutation          SNP   \n",
      "15216    missense_variant      Missense_Mutation          SNP   \n",
      "15218    missense_variant      Missense_Mutation          SNP   \n",
      "\n",
      "      Reference_Allele Tumor_Seq_Allele2   SAMPLE_ID Sequence_Source  \\\n",
      "720                  G                 A  SJDES003-R             WXS   \n",
      "730                  C                 T  SJDES011-R             WXS   \n",
      "783                  C                 T    SJDES017             WXS   \n",
      "813                  T                 C    SJDES005             WXS   \n",
      "829                  G                 A     03-P152             WXS   \n",
      "...                ...               ...         ...             ...   \n",
      "15134                C                 T    SJDES006             WXS   \n",
      "15155                -                 C    SJDES010             WXS   \n",
      "15191                C                 A      TTC466             WXS   \n",
      "15216                C                 T      TTC466             WXS   \n",
      "15218                T                 C      TTC466             WXS   \n",
      "\n",
      "                             HGVSc              HGVSp  HGVSp_Short  \\\n",
      "720     ENST00000374736.3:c.806C>T        p.Ala269Val      p.A269V   \n",
      "730    ENST00000301732.5:c.2965G>A        p.Ala989Thr      p.A989T   \n",
      "783    ENST00000261200.4:c.4562G>A       p.Arg1521Gln     p.R1521Q   \n",
      "813     ENST00000353139.5:c.605A>G        p.Asn202Ser      p.N202S   \n",
      "829    ENST00000302913.4:c.1257C>T          p.Pro419=      p.P419=   \n",
      "...                            ...                ...          ...   \n",
      "15134   ENST00000218089.9:c.646C>T        p.Arg216Ter      p.R216*   \n",
      "15155    ENST00000373367.3:c.36dup  p.Leu13AlafsTer30  p.L13Afs*30   \n",
      "15191  ENST00000342160.3:c.8615G>T       p.Gly2872Val     p.G2872V   \n",
      "15216  ENST00000376020.2:c.3442G>A       p.Glu1148Lys     p.E1148K   \n",
      "15218   ENST00000370536.2:c.512A>G        p.Lys171Arg      p.K171R   \n",
      "\n",
      "         Transcript_ID          RefSeq  Protein_position  \n",
      "720    ENST00000374736     NM_005502.3             269.0  \n",
      "730    ENST00000301732     NM_001089.2             989.0  \n",
      "783    ENST00000261200     NM_020297.2            1521.0  \n",
      "813    ENST00000353139     NM_198834.1             202.0  \n",
      "829    ENST00000302913     NM_015831.2             419.0  \n",
      "...                ...             ...               ...  \n",
      "15134  ENST00000218089  NM_001042749.1             216.0  \n",
      "15155  ENST00000373367     NM_144969.2              12.0  \n",
      "15191  ENST00000342160             NaN            2872.0  \n",
      "15216  ENST00000376020     NM_020717.3            1148.0  \n",
      "15218  ENST00000370536     NM_005634.2             171.0  \n",
      "\n",
      "[495 rows x 17 columns]\n",
      "\n",
      "DataFrame shape after removing duplicates: (14737, 17)\n"
     ]
    }
   ],
   "source": [
    "# clean variant data\n",
    "\n",
    "# subset for necessary columns\n",
    "mut_df = init_mut_df.filter(['Hugo_Symbol',\n",
    "                        'Chromosome',\n",
    "                        'Start_Position', \n",
    "                        'End_Position',\n",
    "                        'Consequence',\n",
    "                        'Variant_Classification',\n",
    "                        'Variant_Type',\n",
    "                        'Reference_Allele',\n",
    "                        'Tumor_Seq_Allele2',\n",
    "                        'Tumor_Sample_Barcode',\n",
    "                        'Sequence_Source',\n",
    "                        'HGVSc',\n",
    "                        'HGVSp',\n",
    "                        'HGVSp_Short',\n",
    "                        'Transcript_ID',\n",
    "                        'RefSeq',\n",
    "                        'Protein_position'\n",
    "                       ], axis=1)\n",
    "\n",
    "\n",
    "# Strip whitespace and retry\n",
    "mut_df.columns = mut_df.columns.str.strip()\n",
    "mut_df = mut_df.rename(columns={'Tumor_Sample_Barcode': 'SAMPLE_ID'})\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = mut_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# TODO check duplicates for sanity check\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(mut_df[mut_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# save duplicate rows to file\n",
    "    dupes = mut_df[mut_df.duplicated(keep=False)]\n",
    "    mut_df.to_csv('mut_dupes.csv', index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "# remove duplicates, but keep first occurrence\n",
    "    mut_df = mut_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {mut_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "\n",
    "    \n",
    "# print(mut_df.columns)\n",
    "# # print(mut_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75f3d6c8-9257-4ac6-b883-75a967ba8592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT_ID', 'AGE', 'SEX', 'ETHNICITY'], dtype='object')\n",
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# clean patient data\n",
    "# print(patient_df.shape)\n",
    "# print(patient_df.columns)\n",
    "\n",
    "# subset data\n",
    "# subset for necessary columns\n",
    "patient_df = init_patient_df.filter(['PATIENT_ID',\n",
    "                        'AGE',\n",
    "                        'SEX', \n",
    "                        'ETHNICITY',\n",
    "                        'Consequence'\n",
    "                       ], axis=1)\n",
    "\n",
    "print(patient_df.columns)\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = patient_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(patient_df[patient_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    patient_df = patient_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {patient_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb2499e2-affb-404e-b970-04aa20bef06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT_ID', 'SAMPLE_ID', 'SAMPLE_CLASS', 'ONCOTREE_CODE',\n",
      "       'CANCER_TYPE', 'CANCER_TYPE_DETAILED', 'TMB_NONSYNONYMOUS'],\n",
      "      dtype='object')\n",
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# clean sample data\n",
    "\n",
    "# print(sample_df.shape)\n",
    "# print(sample_df.columns)\n",
    "# print(sample_df.head())\n",
    "\n",
    "\n",
    "# subset data\n",
    "# subset for necessary columns\n",
    "sample_df = init_sample_df.filter(['PATIENT_ID',\n",
    "                                     'SAMPLE_ID',\n",
    "                                     'SAMPLE_CLASS',\n",
    "                                     'ONCOTREE_CODE',\n",
    "                                     'CANCER_TYPE',\n",
    "                                     'CANCER_TYPE_DETAILED',\n",
    "                                     'TMB_NONSYNONYMOUS'\n",
    "                                    ], axis=1)\n",
    "\n",
    "\n",
    "print(sample_df.columns)\n",
    "\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = sample_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(sample_df[sample_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    sample_df = sample_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {sample_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca4cd556-6160-44dd-9c56-f7f27a387f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataframes\n",
    "## TODO: redo so that all columns are available and that records with no samples will be there. \"left outer join\"? will get NAs.\n",
    "\n",
    "init_combined_df = mut_df.merge(sample_df, on='SAMPLE_ID', how='left')\n",
    "\n",
    "# print(mut_df.columns)\n",
    "# print(mut_df.shape)\n",
    "\n",
    "# print(sample_df.columns)\n",
    "# print(sample_df.shape)\n",
    "\n",
    "# print(init_combined_df.columns)\n",
    "# print(init_combined_df.shape)\n",
    "\n",
    "#add patient_df\n",
    "combined_df = init_combined_df.merge(patient_df, on='PATIENT_ID', how='left')\n",
    "\n",
    "# print(patient_df.columns)\n",
    "# print(patient_df.shape)\n",
    "\n",
    "# print(combined_df.columns)\n",
    "# print(combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c2fd3ee-02fc-48bf-acc9-7675137eea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add column for study id\n",
    "study_id = init_study_meta.iloc[0, 0]\n",
    "study_id = study_id.replace('cancer_study_identifier: ', '')\n",
    "# study_id\n",
    "combined_df['STUDY_ID'] = study_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aee6b500-7a61-4190-934b-53c7055686b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = combined_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(combined_df[combined_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {combined_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b0bcca1-476e-4e77-a0a1-bb3a3bab9b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (14737, 27)\n",
      "Removed 3123 rows where SAMPLE_CLASS == 'Cell line'\n",
      "New shape: (11614, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SAMPLE_CLASS\n",
       "Cell line    3123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# remove cell lines\n",
    "\n",
    "original_shape = combined_df.shape\n",
    "print(f\"Original shape: {original_shape}\")\n",
    "\n",
    "#lines to remove\n",
    "removed_df = combined_df[combined_df['SAMPLE_CLASS'] == 'Cell line']\n",
    "\n",
    "# remove cell lines\n",
    "filtered_df = combined_df[combined_df['SAMPLE_CLASS'] != 'Cell line']\n",
    "\n",
    "# calculate how many rows were removed\n",
    "rows_removed = original_shape[0] - filtered_df.shape[0]\n",
    "print(f\"Removed {rows_removed} rows where SAMPLE_CLASS == 'Cell line'\")\n",
    "\n",
    "# print new shape\n",
    "print(f\"New shape: {filtered_df.shape}\")\n",
    "\n",
    "# reassign df\n",
    "combined_df = filtered_df\n",
    "\n",
    "removed_df.to_csv('cell_lines_removed.csv', index=False)\n",
    "removed_df.value_counts(\"SAMPLE_CLASS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96f130c2-8fd1-481b-8f5a-00db0ded9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Value counts written for 27 columns to folder: value_counts_by_column\n"
     ]
    }
   ],
   "source": [
    "# combined_df.isna().sum()\n",
    "\n",
    "# Hugo_Symbol                   0\n",
    "# Chromosome                    0\n",
    "# Start_Position                0\n",
    "# End_Position                  0\n",
    "# Consequence                 124 - some of the Variant_Classification=Silent have no consequence described\n",
    "# Variant_Classification        0\n",
    "# Variant_Type                  0\n",
    "# Reference_Allele              0\n",
    "# Tumor_Seq_Allele2             0\n",
    "# SAMPLE_ID                     0\n",
    "# Sequence_Source               0\n",
    "# HGVSc                       136 - some of the Variant_Classification=Silent and all of the Variant_Classification=3'Flank and 5'Flank\n",
    "# HGVSp                       346 \n",
    "# Transcript_ID               124 - some of the Variant_Classification=Silent have no Transcript_ID described\n",
    "# RefSeq                     1338\n",
    "# Protein_position            334\n",
    "# Gnomad_Notation               0\n",
    "# PATIENT_ID                    0\n",
    "# SAMPLE_CLASS                  0\n",
    "# ONCOTREE_CODE                 0\n",
    "# CANCER_TYPE                   0\n",
    "# CANCER_TYPE_DETAILED          0\n",
    "# TMB_NONSYNONYMOUS             0\n",
    "# AGE                        4745 - some ages undisclosed\n",
    "# SEX                           0\n",
    "# ETHNICITY                 10900 - many patients' ethnicities undisclosed\n",
    "# STUDY_ID                      0\n",
    "\n",
    "\n",
    "# define output folder (will create it if needed)\n",
    "output_dir = \"value_counts_by_column\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# loop through each column\n",
    "for col in combined_df.columns:\n",
    "    # build filename\n",
    "    filename = f\"value_counts_{col}.txt\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # write counts to file\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(f\"Value counts for column: {col}\\n\\n\")\n",
    "        f.write(combined_df[col].value_counts(dropna=False).to_string())\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"✅ Value counts written for {len(combined_df.columns)} columns to folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b032d44-fcdd-45c1-b4cb-6d42c6b23894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hugo_Symbol                  0\n",
       "Chromosome                   0\n",
       "Start_Position               0\n",
       "End_Position                 0\n",
       "Consequence                  0\n",
       "Variant_Classification       0\n",
       "Variant_Type                 0\n",
       "Reference_Allele             0\n",
       "Tumor_Seq_Allele2            0\n",
       "SAMPLE_ID                    0\n",
       "Sequence_Source              0\n",
       "HGVSc                      136\n",
       "HGVSp                      346\n",
       "HGVSp_Short                136\n",
       "Transcript_ID              124\n",
       "RefSeq                    1338\n",
       "Protein_position           334\n",
       "PATIENT_ID                   0\n",
       "SAMPLE_CLASS                 0\n",
       "ONCOTREE_CODE                0\n",
       "CANCER_TYPE                  0\n",
       "CANCER_TYPE_DETAILED         0\n",
       "TMB_NONSYNONYMOUS            0\n",
       "AGE                          0\n",
       "SEX                          0\n",
       "ETHNICITY                    0\n",
       "STUDY_ID                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filling in NaNs - AGE, ETHNICITY, Consequence\n",
    "# TODO add consequence with annotation\n",
    "\n",
    "cols_to_fill = ['Consequence', 'AGE', 'ETHNICITY']\n",
    "fill_value = \"No_Data\"\n",
    "\n",
    "for col in cols_to_fill:\n",
    "    combined_df[col] = combined_df[col].fillna(fill_value)\n",
    "\n",
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2184b27-ab42-4734-8994-e4ab1d235d9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2580060520.py, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[54], line 66\u001b[0;36m\u001b[0m\n\u001b[0;31m    def chr23_to_Y(variant: str) _> str:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "# correcting chromosome 23 to chromosome X or Y\n",
    "\n",
    "# TODO. look at gene and see whether it maps to x or y for males\n",
    "combined_df.to_csv('output0.csv', index=False)\n",
    "\n",
    "#1 - try these examples in GUI\n",
    "# 23-153175777-G-A\n",
    "# 23-134494503-C-T\n",
    "# 23-153223671-C-T\n",
    "## yes these work\n",
    "\n",
    "#2 - try this exampe programmatically\n",
    "# 23-153175777-G-A  -----   ARHGAP4\n",
    "\n",
    "# gnomAD  = \"X-153175777-G-A\"\n",
    "# assembly = \"GRCh37\"                   # or \"GRCh38\"\n",
    "# https:/normalize.cancervariants.org/variation/normalize?q=x-153223671-C-T\n",
    "BASE_URL = \"https://normalize.cancervariants.org/variation/\"\n",
    "HEADERS = {\"Accept\": \"application/json\"}\n",
    "\n",
    "\n",
    "def test_tokenization(gnomAD):\n",
    "    \"\"\"Fetch gene from VICC variation normalizer\"\"\"\n",
    "    url = f\"{BASE_URL}normalize?q={gnomAD}\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def chr23_females(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert Chromosome 23 to 'X' for rows where SEX is female.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns 'Chromosome' and 'SEX'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        The same DataFrame (modified in place) so you can chain if desired.\n",
    "    \"\"\"\n",
    "    # Ensure we’re comparing like with like\n",
    "    chr_col = df[\"Chromosome\"].astype(str).str.strip()\n",
    "    sex_col = df[\"SEX\"].astype(str).str.upper().str.strip()   # handles 'F', 'f', 'Female', etc.\n",
    "    \n",
    "    mask = (chr_col == \"23\") & (sex_col.str.startswith(\"F\"))\n",
    "    df.loc[mask, \"Chromosome\"] = \"X\"\n",
    "    return df\n",
    "\n",
    "combined_df = chr23_females(combined_df)\n",
    "combined_df.to_csv('output_post_Female_X.csv', index=False)\n",
    "\n",
    "variant = \"23-153175777-G-A\"\n",
    "PATTERN = re.compile(r'^23-')        # anchored ^ so only the chromosome prefix is substituted\n",
    "gene = \"ARHGAP4\"\n",
    "\n",
    "def chr23_to_X(variant: str) -> str:\n",
    "    \"\"\"Return `variant` with leading '23-' swapped to 'X-'; otherwise unchanged.\"\"\"\n",
    "    return PATTERN.sub('X-', variant)\n",
    "def chr23_to_Y(variant: str) _> str:\n",
    "    \"\"\"Return `variant` with leading '23-' swapped to 'Y-'; otherwise unchanged.\"\"\"\n",
    "    return PATTERN.sub('Y-', variant)\n",
    "\n",
    "\n",
    "def chr_23_male_det(variant):\n",
    "    # change to X if position > 60 000 000\n",
    "    pos = int(variant.split('-')[1]) \n",
    "    print(f\"Variant is at position {pos}\")\n",
    "    if pos > 60000000:\n",
    "        print(f\"Variant {variant} is located at a position beyond the length of the Y chromosome.\")\n",
    "        # df[\"Variant\"] = df[\"Variant\"].str.replace(r'^23-', 'X-', regex=True)\n",
    "        new_notation = chr23_to_X(variant)\n",
    "        print(f\"New variant notation: {new_notation}\")\n",
    "    elif pos < 60000000:\n",
    "        print(\"Determining if variant is on X or Y...\")\n",
    "        Y_variant = chr23_to_Y(variant)\n",
    "        print(f\"testing {Y_variant} for tokenization\")\n",
    "        r = test_tokenization(Y_variant)\n",
    "        warnings = r['warnings']\n",
    "        if warnings == \"[]\":\n",
    "            yes_Y_chrom = Y_variant\n",
    "            print(f\"{variant} is present on the Y chromosome\")\n",
    "        else:\n",
    "            print(f\"{variant} is NOT present on the Y chromosome\")\n",
    "        X_variant = chr23_to_X(variant)\n",
    "        print(f\"testing {X_variant} for tokenization\") \n",
    "        r = test_tokenization(X_variant)\n",
    "        warnings = r['warnings']\n",
    "        if warnings != \"[]\":\n",
    "            yes_X_chrom = X_variant\n",
    "            print(f\"{variant} is present on the X chromosome\")\n",
    "        else:\n",
    "            print(f\"{variant} is NOT present on the X chromosome\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        print Y_variant\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def chr_23_males(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Where SEX is Male and Chromosome is 23, apply a series of checks:\n",
    "\n",
    "#     • If Start_Position > 60,000,000  → set Chromosome to 'X'.\n",
    "#     • Otherwise build gnomAD notation twice (Y-chromosome and X-chromosome),\n",
    "#       run `test_tokenization()` on each, and:\n",
    "#         – if only X succeeds → Chromosome = 'X'\n",
    "#         – if only Y succeeds → Chromosome = 'Y'\n",
    "#         – if both or neither succeed → leave as 23 and flag the row.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         The same DataFrame (modified in place).\n",
    "#     \"\"\"\n",
    "#     # normalize columns\n",
    "#     chr_col = df[\"Chromosome\"].astype(str).str.strip()\n",
    "#     sex_col = df[\"SEX\"].astype(str).str.upper().str.strip()\n",
    "#     pos_col = df[\"Start_Position\"]\n",
    "\n",
    "#     # rows that are chr 23 **and** male\n",
    "#     mask_male_23 = (chr_col == \"23\") & sex_col.str.startswith(\"M\")\n",
    "\n",
    "#     # STEP 1\n",
    "#     # change to X if position > 60 000 000\n",
    "#     mask_high_pos = mask_male_23 & (pos_col > 60_000_000)\n",
    "#     df.loc[mask_high_pos, \"Chromosome\"] = \"X\"\n",
    "\n",
    "#     # STEP 2\n",
    "#     # gnomAD strings and tokenizer checks for the remaining rows\n",
    "#     remaining = mask_male_23 & ~mask_high_pos\n",
    "\n",
    "#     if remaining.any():                         # skip if nothing left\n",
    "#         gnomad_Y = df.loc[remaining].apply(\n",
    "#             lambda r: f\"Y-{r.Start_Position}-{r.Reference_Allele}-{r.Tumor_Seq_Allele2}\",\n",
    "#             axis=1\n",
    "#         )\n",
    "#         gnomad_X = df.loc[remaining].apply(\n",
    "#             lambda r: f\"X-{r.Start_Position}-{r.Reference_Allele}-{r.Tumor_Seq_Allele2}\",\n",
    "#             axis=1\n",
    "#         )\n",
    "\n",
    "#         ok_Y = test_tokenization(gnomad_Y)\n",
    "#         ok_X = test_tokenization(gnomad_X)\n",
    "#         print(ok_Y)\n",
    "#         print(ok_X)\n",
    "\n",
    "#         # rows where only one succeeds\n",
    "#         only_X = remaining & ok_X & ~ok_Y\n",
    "#         only_Y = remaining & ok_Y & ~ok_X\n",
    "\n",
    "#         df.loc[only_X, \"Chromosome\"] = \"X\"\n",
    "#         df.loc[only_Y, \"Chromosome\"] = \"Y\"\n",
    "\n",
    "#         # rows where result is ambiguous → flag\n",
    "#         ambiguous = remaining & ~(only_X | only_Y)\n",
    "#         df.loc[ambiguous, \"XY_flagged\"] = True\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "chr23_females(combined_df)\n",
    "chr_23_males (combined_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# combined_df = chr23_females(combined_df)\n",
    "# position 1428413\n",
    "\n",
    "\n",
    "\n",
    "# r = test_tokenization(\"X-153175777-G-A\")\n",
    "# r\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # write to file\n",
    "combined_df.to_csv('output2.csv', index=False)\n",
    "\n",
    "# print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99608997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct Gnomad variant ID column\n",
    "combined_df[\"Gnomad_Notation\"] = combined_df.apply(\n",
    "    lambda row: f\"{row['Chromosome']}-{row['Start_Position']}-{row['Reference_Allele']}-{row['Tumor_Seq_Allele2']}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131ab23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ef311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 134 rows with duplicated Gnomad_Notation per PATIENT_ID.\n"
     ]
    }
   ],
   "source": [
    "# remove variant dupes per patient\n",
    "\n",
    "# find duplicated (PATIENT_ID, Gnomad_Notation) pairs\n",
    "dupe_mask = combined_df.duplicated(subset=[\"PATIENT_ID\", \"Gnomad_Notation\"], keep=\"first\")\n",
    "# new DataFrame with the duplicated rows\n",
    "patient_variant_dupes = combined_df[dupe_mask]\n",
    "# remove those rows from the original DataFrame\n",
    "combined_df_cleaned = combined_df[~dupe_mask]\n",
    "# write removed rows to file\n",
    "patient_variant_dupes.to_csv(\"patient_variant_dupes.csv\", index=False)\n",
    "# print the number of rows removed\n",
    "print(f\"Removed {patient_variant_dupes.shape[0]} rows with duplicated Gnomad_Notation per PATIENT_ID.\")\n",
    "# reassign dataframe:\n",
    "combined_df = combined_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a1e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
