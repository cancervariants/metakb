{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a47b6a03-4a0f-480f-bb9a-cc2dc0d33f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pprint\n",
    "from urllib.parse import quote_plus  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c12bcf-8cce-4398-be55-bcc103525efb",
   "metadata": {},
   "source": [
    "### DFCI_2014_PES study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3b6784-eadb-4f80-bf38-d376e31f0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "#TODO import as objects from harvester\n",
    "## add parameter to skip first 4 lines in patient and study sample data\n",
    "\n",
    "init_mut_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_mutations.txt', sep='\\t')\n",
    "init_study_meta = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/meta_study.txt', sep='\\t')\n",
    "init_patient_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_clinical_patient.txt', sep='\\t', skiprows=4)\n",
    "init_sample_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_clinical_sample.txt', sep='\\t', skiprows=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b19a85c8-3894-467e-9c4f-c38549a96f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows : 495\n",
      "\n",
      "Duplicate rows (excluding first instance):\n",
      "      Hugo_Symbol Chromosome  Start_Position  End_Position  \\\n",
      "720         ABCA1          9       107607765     107607765   \n",
      "730         ABCA3         16         2338066       2338066   \n",
      "783         ABCC9         12        21954066      21954066   \n",
      "813         ACACA         17        35640173      35640173   \n",
      "829          ACHE          7       100490251     100490251   \n",
      "...           ...        ...             ...           ...   \n",
      "15134       STAG2          X       123179197     123179197   \n",
      "15155     ZDHHC15          X        74742823      74742824   \n",
      "15191       HUWE1          X        53579734      53579734   \n",
      "15216     SHROOM4          X        50350700      50350700   \n",
      "15218        SOX3          X       139586714     139586714   \n",
      "\n",
      "              Consequence Variant_Classification Variant_Type  \\\n",
      "720      missense_variant      Missense_Mutation          SNP   \n",
      "730      missense_variant      Missense_Mutation          SNP   \n",
      "783      missense_variant      Missense_Mutation          SNP   \n",
      "813      missense_variant      Missense_Mutation          SNP   \n",
      "829    synonymous_variant                 Silent          SNP   \n",
      "...                   ...                    ...          ...   \n",
      "15134         stop_gained      Nonsense_Mutation          SNP   \n",
      "15155  frameshift_variant        Frame_Shift_Ins          INS   \n",
      "15191    missense_variant      Missense_Mutation          SNP   \n",
      "15216    missense_variant      Missense_Mutation          SNP   \n",
      "15218    missense_variant      Missense_Mutation          SNP   \n",
      "\n",
      "      Reference_Allele Tumor_Seq_Allele2   SAMPLE_ID Sequence_Source  \\\n",
      "720                  G                 A  SJDES003-R             WXS   \n",
      "730                  C                 T  SJDES011-R             WXS   \n",
      "783                  C                 T    SJDES017             WXS   \n",
      "813                  T                 C    SJDES005             WXS   \n",
      "829                  G                 A     03-P152             WXS   \n",
      "...                ...               ...         ...             ...   \n",
      "15134                C                 T    SJDES006             WXS   \n",
      "15155                -                 C    SJDES010             WXS   \n",
      "15191                C                 A      TTC466             WXS   \n",
      "15216                C                 T      TTC466             WXS   \n",
      "15218                T                 C      TTC466             WXS   \n",
      "\n",
      "                             HGVSc              HGVSp  HGVSp_Short  \\\n",
      "720     ENST00000374736.3:c.806C>T        p.Ala269Val      p.A269V   \n",
      "730    ENST00000301732.5:c.2965G>A        p.Ala989Thr      p.A989T   \n",
      "783    ENST00000261200.4:c.4562G>A       p.Arg1521Gln     p.R1521Q   \n",
      "813     ENST00000353139.5:c.605A>G        p.Asn202Ser      p.N202S   \n",
      "829    ENST00000302913.4:c.1257C>T          p.Pro419=      p.P419=   \n",
      "...                            ...                ...          ...   \n",
      "15134   ENST00000218089.9:c.646C>T        p.Arg216Ter      p.R216*   \n",
      "15155    ENST00000373367.3:c.36dup  p.Leu13AlafsTer30  p.L13Afs*30   \n",
      "15191  ENST00000342160.3:c.8615G>T       p.Gly2872Val     p.G2872V   \n",
      "15216  ENST00000376020.2:c.3442G>A       p.Glu1148Lys     p.E1148K   \n",
      "15218   ENST00000370536.2:c.512A>G        p.Lys171Arg      p.K171R   \n",
      "\n",
      "         Transcript_ID          RefSeq  Protein_position  \n",
      "720    ENST00000374736     NM_005502.3             269.0  \n",
      "730    ENST00000301732     NM_001089.2             989.0  \n",
      "783    ENST00000261200     NM_020297.2            1521.0  \n",
      "813    ENST00000353139     NM_198834.1             202.0  \n",
      "829    ENST00000302913     NM_015831.2             419.0  \n",
      "...                ...             ...               ...  \n",
      "15134  ENST00000218089  NM_001042749.1             216.0  \n",
      "15155  ENST00000373367     NM_144969.2              12.0  \n",
      "15191  ENST00000342160             NaN            2872.0  \n",
      "15216  ENST00000376020     NM_020717.3            1148.0  \n",
      "15218  ENST00000370536     NM_005634.2             171.0  \n",
      "\n",
      "[495 rows x 17 columns]\n",
      "\n",
      "DataFrame shape after removing duplicates: (14737, 17)\n"
     ]
    }
   ],
   "source": [
    "# clean variant data\n",
    "\n",
    "# subset for necessary columns\n",
    "mut_df = init_mut_df.filter(['Hugo_Symbol',\n",
    "                        'Chromosome',\n",
    "                        'Start_Position', \n",
    "                        'End_Position',\n",
    "                        'Consequence',\n",
    "                        'Variant_Classification',\n",
    "                        'Variant_Type',\n",
    "                        'Reference_Allele',\n",
    "                        'Tumor_Seq_Allele2',\n",
    "                        'Tumor_Sample_Barcode',\n",
    "                        'Sequence_Source',\n",
    "                        'HGVSc',\n",
    "                        'HGVSp',\n",
    "                        'HGVSp_Short',\n",
    "                        'Transcript_ID',\n",
    "                        'RefSeq',\n",
    "                        'Protein_position'\n",
    "                       ], axis=1)\n",
    "\n",
    "\n",
    "# Strip whitespace and retry\n",
    "mut_df.columns = mut_df.columns.str.strip()\n",
    "mut_df = mut_df.rename(columns={'Tumor_Sample_Barcode': 'SAMPLE_ID'})\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = mut_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# TODO check duplicates for sanity check\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(mut_df[mut_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# save duplicate rows to file\n",
    "    dupes = mut_df[mut_df.duplicated(keep=False)]\n",
    "    mut_df.to_csv('mut_dupes.csv', index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "# remove duplicates, but keep first occurrence\n",
    "    mut_df = mut_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {mut_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "\n",
    "    \n",
    "# print(mut_df.columns)\n",
    "# # print(mut_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75f3d6c8-9257-4ac6-b883-75a967ba8592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT_ID', 'AGE', 'SEX', 'ETHNICITY'], dtype='object')\n",
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# clean patient data\n",
    "# print(patient_df.shape)\n",
    "# print(patient_df.columns)\n",
    "\n",
    "# subset data\n",
    "# subset for necessary columns\n",
    "patient_df = init_patient_df.filter(['PATIENT_ID',\n",
    "                        'AGE',\n",
    "                        'SEX', \n",
    "                        'ETHNICITY',\n",
    "                        'Consequence'\n",
    "                       ], axis=1)\n",
    "\n",
    "print(patient_df.columns)\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = patient_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(patient_df[patient_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    patient_df = patient_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {patient_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb2499e2-affb-404e-b970-04aa20bef06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT_ID', 'SAMPLE_ID', 'SAMPLE_CLASS', 'ONCOTREE_CODE',\n",
      "       'CANCER_TYPE', 'CANCER_TYPE_DETAILED', 'TMB_NONSYNONYMOUS'],\n",
      "      dtype='object')\n",
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# clean sample data\n",
    "\n",
    "# print(sample_df.shape)\n",
    "# print(sample_df.columns)\n",
    "# print(sample_df.head())\n",
    "\n",
    "\n",
    "# subset data\n",
    "# subset for necessary columns\n",
    "sample_df = init_sample_df.filter(['PATIENT_ID',\n",
    "                                     'SAMPLE_ID',\n",
    "                                     'SAMPLE_CLASS',\n",
    "                                     'ONCOTREE_CODE',\n",
    "                                     'CANCER_TYPE',\n",
    "                                     'CANCER_TYPE_DETAILED',\n",
    "                                     'TMB_NONSYNONYMOUS'\n",
    "                                    ], axis=1)\n",
    "\n",
    "\n",
    "print(sample_df.columns)\n",
    "\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = sample_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(sample_df[sample_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    sample_df = sample_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {sample_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca4cd556-6160-44dd-9c56-f7f27a387f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataframes\n",
    "## TODO: redo so that all columns are available and that records with no samples will be there. \"left outer join\"? will get NAs.\n",
    "\n",
    "init_combined_df = mut_df.merge(sample_df, on='SAMPLE_ID', how='left')\n",
    "\n",
    "# print(mut_df.columns)\n",
    "# print(mut_df.shape)\n",
    "\n",
    "# print(sample_df.columns)\n",
    "# print(sample_df.shape)\n",
    "\n",
    "# print(init_combined_df.columns)\n",
    "# print(init_combined_df.shape)\n",
    "\n",
    "#add patient_df\n",
    "combined_df = init_combined_df.merge(patient_df, on='PATIENT_ID', how='left')\n",
    "\n",
    "# print(patient_df.columns)\n",
    "# print(patient_df.shape)\n",
    "\n",
    "# print(combined_df.columns)\n",
    "# print(combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c2fd3ee-02fc-48bf-acc9-7675137eea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add column for study id\n",
    "study_id = init_study_meta.iloc[0, 0]\n",
    "study_id = study_id.replace('cancer_study_identifier: ', '')\n",
    "# study_id\n",
    "combined_df['STUDY_ID'] = study_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aee6b500-7a61-4190-934b-53c7055686b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = combined_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(combined_df[combined_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {combined_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b0bcca1-476e-4e77-a0a1-bb3a3bab9b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (14737, 27)\n",
      "Removed 3123 rows where SAMPLE_CLASS == 'Cell line'\n",
      "New shape: (11614, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SAMPLE_CLASS\n",
       "Cell line    3123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# remove cell lines\n",
    "\n",
    "original_shape = combined_df.shape\n",
    "print(f\"Original shape: {original_shape}\")\n",
    "\n",
    "#lines to remove\n",
    "removed_df = combined_df[combined_df['SAMPLE_CLASS'] == 'Cell line']\n",
    "\n",
    "# remove cell lines\n",
    "filtered_df = combined_df[combined_df['SAMPLE_CLASS'] != 'Cell line']\n",
    "\n",
    "# calculate how many rows were removed\n",
    "rows_removed = original_shape[0] - filtered_df.shape[0]\n",
    "print(f\"Removed {rows_removed} rows where SAMPLE_CLASS == 'Cell line'\")\n",
    "\n",
    "# print new shape\n",
    "print(f\"New shape: {filtered_df.shape}\")\n",
    "\n",
    "# reassign df\n",
    "combined_df = filtered_df\n",
    "\n",
    "removed_df.to_csv('cell_lines_removed.csv', index=False)\n",
    "removed_df.value_counts(\"SAMPLE_CLASS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96f130c2-8fd1-481b-8f5a-00db0ded9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Value counts written for 27 columns to folder: value_counts_by_column\n"
     ]
    }
   ],
   "source": [
    "# combined_df.isna().sum()\n",
    "\n",
    "# Hugo_Symbol                   0\n",
    "# Chromosome                    0\n",
    "# Start_Position                0\n",
    "# End_Position                  0\n",
    "# Consequence                 124 - some of the Variant_Classification=Silent have no consequence described\n",
    "# Variant_Classification        0\n",
    "# Variant_Type                  0\n",
    "# Reference_Allele              0\n",
    "# Tumor_Seq_Allele2             0\n",
    "# SAMPLE_ID                     0\n",
    "# Sequence_Source               0\n",
    "# HGVSc                       136 - some of the Variant_Classification=Silent and all of the Variant_Classification=3'Flank and 5'Flank\n",
    "# HGVSp                       346 \n",
    "# Transcript_ID               124 - some of the Variant_Classification=Silent have no Transcript_ID described\n",
    "# RefSeq                     1338\n",
    "# Protein_position            334\n",
    "# Gnomad_Notation               0\n",
    "# PATIENT_ID                    0\n",
    "# SAMPLE_CLASS                  0\n",
    "# ONCOTREE_CODE                 0\n",
    "# CANCER_TYPE                   0\n",
    "# CANCER_TYPE_DETAILED          0\n",
    "# TMB_NONSYNONYMOUS             0\n",
    "# AGE                        4745 - some ages undisclosed\n",
    "# SEX                           0\n",
    "# ETHNICITY                 10900 - many patients' ethnicities undisclosed\n",
    "# STUDY_ID                      0\n",
    "\n",
    "\n",
    "# define output folder (will create it if needed)\n",
    "output_dir = \"value_counts_by_column\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# loop through each column\n",
    "for col in combined_df.columns:\n",
    "    # build filename\n",
    "    filename = f\"value_counts_{col}.txt\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # write counts to file\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(f\"Value counts for column: {col}\\n\\n\")\n",
    "        f.write(combined_df[col].value_counts(dropna=False).to_string())\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"✅ Value counts written for {len(combined_df.columns)} columns to folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b032d44-fcdd-45c1-b4cb-6d42c6b23894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hugo_Symbol                  0\n",
       "Chromosome                   0\n",
       "Start_Position               0\n",
       "End_Position                 0\n",
       "Consequence                  0\n",
       "Variant_Classification       0\n",
       "Variant_Type                 0\n",
       "Reference_Allele             0\n",
       "Tumor_Seq_Allele2            0\n",
       "SAMPLE_ID                    0\n",
       "Sequence_Source              0\n",
       "HGVSc                      136\n",
       "HGVSp                      346\n",
       "HGVSp_Short                136\n",
       "Transcript_ID              124\n",
       "RefSeq                    1338\n",
       "Protein_position           334\n",
       "PATIENT_ID                   0\n",
       "SAMPLE_CLASS                 0\n",
       "ONCOTREE_CODE                0\n",
       "CANCER_TYPE                  0\n",
       "CANCER_TYPE_DETAILED         0\n",
       "TMB_NONSYNONYMOUS            0\n",
       "AGE                          0\n",
       "SEX                          0\n",
       "ETHNICITY                    0\n",
       "STUDY_ID                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filling in NaNs - AGE, ETHNICITY, Consequence\n",
    "# TODO add consequence with annotation\n",
    "\n",
    "cols_to_fill = ['Consequence', 'AGE', 'ETHNICITY']\n",
    "fill_value = \"No_Data\"\n",
    "\n",
    "for col in cols_to_fill:\n",
    "    combined_df[col] = combined_df[col].fillna(fill_value)\n",
    "\n",
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2184b27-ab42-4734-8994-e4ab1d235d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged row 15: male, X, passes tokenization\n",
      "Flagged row 16: male, X, passes tokenization\n",
      "Flagged row 17: male, X, passes tokenization\n",
      "Flagged row 18: male, X, passes tokenization\n",
      "Flagged row 19: male, X, passes tokenization\n",
      "Flagged row 20: male, X, passes tokenization\n",
      "Flagged row 21: male, X, passes tokenization\n",
      "Flagged row 22: male, X, passes tokenization\n",
      "Flagged row 23: male, X, passes tokenization\n",
      "Flagged row 24: male, X, passes tokenization\n",
      "Flagged row 25: male, X, passes tokenization\n",
      "Flagged row 26: male, X, passes tokenization\n",
      "Flagged row 27: male, X, passes tokenization\n",
      "Flagged row 28: male, X, passes tokenization\n",
      "Flagged row 29: male, X, passes tokenization\n",
      "Flagged row 30: male, X, passes tokenization\n",
      "Flagged row 31: male, X, passes tokenization\n",
      "Flagged row 32: male, X, passes tokenization\n",
      "Flagged row 33: male, X, passes tokenization\n",
      "Flagged row 34: male, X, passes tokenization\n",
      "Flagged row 35: male, X, passes tokenization\n",
      "Flagged row 36: male, X, passes tokenization\n",
      "Flagged row 37: male, X, passes tokenization\n",
      "Flagged row 38: male, X, passes tokenization\n",
      "Flagged row 39: male, X, passes tokenization\n",
      "Flagged row 40: male, X, passes tokenization\n",
      "Flagged row 41: male, X, passes tokenization\n",
      "Flagged row 42: male, X, passes tokenization\n",
      "Flagged row 43: male, X, passes tokenization\n",
      "Flagged row 44: male, X, passes tokenization\n",
      "Flagged row 45: male, X, passes tokenization\n",
      "Flagged row 46: male, X, passes tokenization\n",
      "Flagged row 47: male, X, passes tokenization\n",
      "Flagged row 48: male, X, passes tokenization\n",
      "Flagged row 49: male, X, passes tokenization\n",
      "Flagged row 50: male, X, passes tokenization\n",
      "Flagged row 51: male, X, passes tokenization\n",
      "Flagged row 52: male, X, passes tokenization\n",
      "Flagged row 56: male, X, passes tokenization\n",
      "Flagged row 64: male, X, passes tokenization\n",
      "Flagged row 84: male, X, passes tokenization\n",
      "Flagged row 85: male, X, passes tokenization\n",
      "Flagged row 86: male, X, passes tokenization\n",
      "Flagged row 87: male, X, passes tokenization\n",
      "Flagged row 88: male, X, passes tokenization\n",
      "Flagged row 89: male, X, passes tokenization\n",
      "Flagged row 90: male, X, passes tokenization\n",
      "Flagged row 91: male, X, passes tokenization\n",
      "Flagged row 92: male, X, passes tokenization\n",
      "Flagged row 93: male, X, passes tokenization\n",
      "Flagged row 94: male, X, passes tokenization\n",
      "Flagged row 95: male, X, passes tokenization\n",
      "Flagged row 96: male, X, passes tokenization\n",
      "Flagged row 97: male, X, passes tokenization\n",
      "Flagged row 98: male, X, passes tokenization\n",
      "Flagged row 99: male, X, passes tokenization\n",
      "Flagged row 100: male, X, passes tokenization\n",
      "Flagged row 101: male, X, passes tokenization\n",
      "Flagged row 102: male, X, passes tokenization\n",
      "Flagged row 103: male, X, passes tokenization\n",
      "Flagged row 104: male, X, passes tokenization\n",
      "Flagged row 105: male, X, passes tokenization\n",
      "Flagged row 106: male, X, passes tokenization\n",
      "Flagged row 107: male, X, passes tokenization\n",
      "Flagged row 108: male, X, passes tokenization\n",
      "Flagged row 109: male, X, passes tokenization\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlagged row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: male, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, passes tokenization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Now run\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mprocess_chr_sex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag_row\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Read each row\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# grab chromosome and sex fields\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# if sex == female, skip\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# if x == True and y == True\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#     flag the row\u001b[39;00m\n\u001b[1;32m     81\u001b[0m r \u001b[38;5;241m=\u001b[39m test_tokenization(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-153175777-G-A\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 46\u001b[0m, in \u001b[0;36mprocess_chr_sex\u001b[0;34m(df, func)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03mCall `func(chromosome, sex, row_index)` for every row.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03mExample `func` might write to a file, populate a dict, etc.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m combined_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mChromosome\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSEX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 60\u001b[0m, in \u001b[0;36mflag_row\u001b[0;34m(chromosome, sex, idx)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chromosome \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# whatever x and y boolean checks are for you\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     x \u001b[38;5;241m=\u001b[39m chromosome \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 60\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mtest_tokenization\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchromosome\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-153175777-G-A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# example call\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mand\u001b[39;00m y:\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlagged row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: male, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, passes tokenization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 25\u001b[0m, in \u001b[0;36mtest_tokenization\u001b[0;34m(gnomAD)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch gene from VICC variation normalizer\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mnormalize?q=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgnomAD\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 25\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEADERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/repos/metakb/venv/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/metakb/venv/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/metakb/venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/repos/metakb/venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/repos/metakb/venv/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/repos/metakb/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/metakb/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/repos/metakb/venv/lib/python3.11/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# correcting chromosome 23 to chromosome X or Y\n",
    "\n",
    "# TODO. look at gene and see whether it maps to x or y for males\n",
    "combined_df.to_csv('output1.csv', index=False)\n",
    "\n",
    "#1 - try these examples in GUI\n",
    "# 23-153175777-G-A\n",
    "# 23-134494503-C-T\n",
    "# 23-153223671-C-T\n",
    "## yes these work\n",
    "\n",
    "#2 - try this exampe programmatically\n",
    "# 23-153175777-G-A  -----   ARHGAP4\n",
    "\n",
    "# gnomAD  = \"X-153175777-G-A\"\n",
    "# assembly = \"GRCh37\"                   # or \"GRCh38\"\n",
    "# https:/normalize.cancervariants.org/variation/normalize?q=x-153223671-C-T\n",
    "BASE_URL = \"https://normalize.cancervariants.org/variation/\"\n",
    "HEADERS = {\"Accept\": \"application/json\"}\n",
    "\n",
    "\n",
    "def test_tokenization(gnomAD):\n",
    "    \"\"\"Fetch gene from VICC variation normalizer\"\"\"\n",
    "    url = f\"{BASE_URL}normalize?q={gnomAD}\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def chr23_females(dataframe) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert Chromosome 23 to 'X' for rows where SEX is female.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns 'Chromosome' and 'SEX'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        The same DataFrame (modified in place) so you can chain if desired.\n",
    "    \"\"\"\n",
    "    # Ensure we’re comparing like with like\n",
    "    chr_col = df[\"Chromosome\"].astype(str).str.strip()\n",
    "    sex_col = df[\"SEX\"].astype(str).str.upper().str.strip()   # handles 'F', 'f', 'Female', etc.\n",
    "    \n",
    "    mask = (chr_col == \"23\") & (sex_col.str.startswith(\"F\"))\n",
    "    df.loc[mask, \"Chromosome\"] = \"X\"\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def chr_23_males(dataframe):\n",
    "        \"\"\"\n",
    "    Where SEX is Male and Chromosome is 23, determine position of variant. If >60,000,000, convert Chromosome 23 to X.\n",
    "    Where SEX is Male and Chromosome is 23, create gnomAD notation with Y as chromosome, run through tokenizer\n",
    "    Where SEX is Male and Chromosome is 23, create gnomAD notation with X as chromosome, run through tokenizer\n",
    "    If results returned for X and not Y, change Chromosome to X\n",
    "    If results returned for Y and not X, change Chromosome to Y\n",
    "    If results returned for both X and Y, flag row\n",
    "    If results returned for neither X nor Y, flag row\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns 'Chromosome' and 'SEX'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        The same DataFrame (modified in place) so you can chain if desired.\n",
    "    \"\"\"\n",
    "    chr_col = df[\"Chromosome\"].astype(str).str.strip()\n",
    "    sex_col = df[\"SEX\"].astype(str).str.upper().str.strip()   # handles 'F', 'f', 'Female', etc.\n",
    "    pos_col = df[\"Start_Position\"] \n",
    "\n",
    "    # rows that are chr 23 **and** male\n",
    "    mask_male_23 = (chr_col == \"23\") & sex_col.str.startswith(\"M\")\n",
    "\n",
    "    # # subset of those where position > 60 000 000\n",
    "    # mask_high_pos = mask_male_23 & (pos_col > 60_000_000)\n",
    "\n",
    "    # # change chromosome to X for these samples\n",
    "    # df.loc[mask_high_pos, \"Chromosome\"] = \"X\"\n",
    "\n",
    "    # create gnomad notations for X and Y, run through VICC normalizer\n",
    "    gnomad_string_Y = df.loc[mask_male_23, :].apply(\n",
    "    lambda r: f\"Y-{r.Start_Position}-{r.Reference_Allele}-{r.Tumor_Seq_Allele2}\",\n",
    "    axis=1\n",
    "    )\n",
    "    json_Y_response = test_tokenization(gnomad_string_Y)\n",
    "\n",
    "\n",
    "    gnomad_string_X = df.loc[mask_male_23, :].apply(\n",
    "    lambda r: f\"X-{r.Start_Position}-{r.Reference_Allele}-{r.Tumor_Seq_Allele2}\",\n",
    "    axis=1\n",
    "    )\n",
    "    json_X_response = test_tokenization(gnomad_string_X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # df.loc[mask, \"Chromosome\"] = \"X\"\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_df = chr23_females(combined_df)\n",
    "position 1428413\n",
    "\n",
    "\n",
    "\n",
    "r = test_tokenization(\"X-153175777-G-A\")\n",
    "r\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # write to file\n",
    "# combined_df.to_csv('output2.csv', index=False)\n",
    "\n",
    "# print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99608997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct Gnomad variant ID column\n",
    "combined_df[\"Gnomad_Notation\"] = combined_df.apply(\n",
    "    lambda row: f\"{row['Chromosome']}-{row['Start_Position']}-{row['Reference_Allele']}-{row['Tumor_Seq_Allele2']}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131ab23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ef311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 134 rows with duplicated Gnomad_Notation per PATIENT_ID.\n"
     ]
    }
   ],
   "source": [
    "# remove variant dupes per patient\n",
    "\n",
    "# find duplicated (PATIENT_ID, Gnomad_Notation) pairs\n",
    "dupe_mask = combined_df.duplicated(subset=[\"PATIENT_ID\", \"Gnomad_Notation\"], keep=\"first\")\n",
    "# new DataFrame with the duplicated rows\n",
    "patient_variant_dupes = combined_df[dupe_mask]\n",
    "# remove those rows from the original DataFrame\n",
    "combined_df_cleaned = combined_df[~dupe_mask]\n",
    "# write removed rows to file\n",
    "patient_variant_dupes.to_csv(\"patient_variant_dupes.csv\", index=False)\n",
    "# print the number of rows removed\n",
    "print(f\"Removed {patient_variant_dupes.shape[0]} rows with duplicated Gnomad_Notation per PATIENT_ID.\")\n",
    "# reassign dataframe:\n",
    "combined_df = combined_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a1e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
