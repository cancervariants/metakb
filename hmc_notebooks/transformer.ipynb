{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a47b6a03-4a0f-480f-bb9a-cc2dc0d33f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c12bcf-8cce-4398-be55-bcc103525efb",
   "metadata": {},
   "source": [
    "### DFCI_2014_PES study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e3b6784-eadb-4f80-bf38-d376e31f0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "#TODO import as objects from harvester\n",
    "## add parameter to skip first 4 lines in patient and study sample data\n",
    "\n",
    "init_mut_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_mutations.txt', sep='\\t')\n",
    "init_study_meta = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/meta_study.txt', sep='\\t')\n",
    "init_patient_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_clinical_patient.txt', sep='\\t', skiprows=4)\n",
    "init_sample_df = pd.read_csv('/Users/costellh/repos/metakb/hmc_notebooks/es_dfarber_broad_2014_extracted/es_dfarber_broad_2014/data_clinical_sample.txt', sep='\\t', skiprows=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b19a85c8-3894-467e-9c4f-c38549a96f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows : 495\n",
      "\n",
      "Duplicate rows (excluding first instance):\n",
      "      Hugo_Symbol Chromosome  Start_Position  End_Position  \\\n",
      "720         ABCA1          9       107607765     107607765   \n",
      "730         ABCA3         16         2338066       2338066   \n",
      "783         ABCC9         12        21954066      21954066   \n",
      "813         ACACA         17        35640173      35640173   \n",
      "829          ACHE          7       100490251     100490251   \n",
      "...           ...        ...             ...           ...   \n",
      "15134       STAG2          X       123179197     123179197   \n",
      "15155     ZDHHC15          X        74742823      74742824   \n",
      "15191       HUWE1          X        53579734      53579734   \n",
      "15216     SHROOM4          X        50350700      50350700   \n",
      "15218        SOX3          X       139586714     139586714   \n",
      "\n",
      "              Consequence Variant_Classification Variant_Type  \\\n",
      "720      missense_variant      Missense_Mutation          SNP   \n",
      "730      missense_variant      Missense_Mutation          SNP   \n",
      "783      missense_variant      Missense_Mutation          SNP   \n",
      "813      missense_variant      Missense_Mutation          SNP   \n",
      "829    synonymous_variant                 Silent          SNP   \n",
      "...                   ...                    ...          ...   \n",
      "15134         stop_gained      Nonsense_Mutation          SNP   \n",
      "15155  frameshift_variant        Frame_Shift_Ins          INS   \n",
      "15191    missense_variant      Missense_Mutation          SNP   \n",
      "15216    missense_variant      Missense_Mutation          SNP   \n",
      "15218    missense_variant      Missense_Mutation          SNP   \n",
      "\n",
      "      Reference_Allele Tumor_Seq_Allele2   SAMPLE_ID Sequence_Source  \\\n",
      "720                  G                 A  SJDES003-R             WXS   \n",
      "730                  C                 T  SJDES011-R             WXS   \n",
      "783                  C                 T    SJDES017             WXS   \n",
      "813                  T                 C    SJDES005             WXS   \n",
      "829                  G                 A     03-P152             WXS   \n",
      "...                ...               ...         ...             ...   \n",
      "15134                C                 T    SJDES006             WXS   \n",
      "15155                -                 C    SJDES010             WXS   \n",
      "15191                C                 A      TTC466             WXS   \n",
      "15216                C                 T      TTC466             WXS   \n",
      "15218                T                 C      TTC466             WXS   \n",
      "\n",
      "                             HGVSc              HGVSp  HGVSp_Short  \\\n",
      "720     ENST00000374736.3:c.806C>T        p.Ala269Val      p.A269V   \n",
      "730    ENST00000301732.5:c.2965G>A        p.Ala989Thr      p.A989T   \n",
      "783    ENST00000261200.4:c.4562G>A       p.Arg1521Gln     p.R1521Q   \n",
      "813     ENST00000353139.5:c.605A>G        p.Asn202Ser      p.N202S   \n",
      "829    ENST00000302913.4:c.1257C>T          p.Pro419=      p.P419=   \n",
      "...                            ...                ...          ...   \n",
      "15134   ENST00000218089.9:c.646C>T        p.Arg216Ter      p.R216*   \n",
      "15155    ENST00000373367.3:c.36dup  p.Leu13AlafsTer30  p.L13Afs*30   \n",
      "15191  ENST00000342160.3:c.8615G>T       p.Gly2872Val     p.G2872V   \n",
      "15216  ENST00000376020.2:c.3442G>A       p.Glu1148Lys     p.E1148K   \n",
      "15218   ENST00000370536.2:c.512A>G        p.Lys171Arg      p.K171R   \n",
      "\n",
      "         Transcript_ID          RefSeq  Protein_position  \n",
      "720    ENST00000374736     NM_005502.3             269.0  \n",
      "730    ENST00000301732     NM_001089.2             989.0  \n",
      "783    ENST00000261200     NM_020297.2            1521.0  \n",
      "813    ENST00000353139     NM_198834.1             202.0  \n",
      "829    ENST00000302913     NM_015831.2             419.0  \n",
      "...                ...             ...               ...  \n",
      "15134  ENST00000218089  NM_001042749.1             216.0  \n",
      "15155  ENST00000373367     NM_144969.2              12.0  \n",
      "15191  ENST00000342160             NaN            2872.0  \n",
      "15216  ENST00000376020     NM_020717.3            1148.0  \n",
      "15218  ENST00000370536     NM_005634.2             171.0  \n",
      "\n",
      "[495 rows x 17 columns]\n",
      "\n",
      "DataFrame shape after removing duplicates: (14737, 17)\n"
     ]
    }
   ],
   "source": [
    "# clean variant data\n",
    "\n",
    "# subset for necessary columns\n",
    "mut_df = init_mut_df.filter(['Hugo_Symbol',\n",
    "                        'Chromosome',\n",
    "                        'Start_Position', \n",
    "                        'End_Position',\n",
    "                        'Consequence',\n",
    "                        'Variant_Classification',\n",
    "                        'Variant_Type',\n",
    "                        'Reference_Allele',\n",
    "                        'Tumor_Seq_Allele2',\n",
    "                        'Tumor_Sample_Barcode',\n",
    "                        'Sequence_Source',\n",
    "                        'HGVSc',\n",
    "                        'HGVSp',\n",
    "                        'HGVSp_Short',\n",
    "                        'Transcript_ID',\n",
    "                        'RefSeq',\n",
    "                        'Protein_position'\n",
    "                       ], axis=1)\n",
    "\n",
    "\n",
    "# Strip whitespace and retry\n",
    "mut_df.columns = mut_df.columns.str.strip()\n",
    "mut_df = mut_df.rename(columns={'Tumor_Sample_Barcode': 'SAMPLE_ID'})\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = mut_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# TODO check duplicates for sanity check\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(mut_df[mut_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# save duplicate rows to file\n",
    "    dupes = mut_df[mut_df.duplicated(keep=False)]\n",
    "    mut_df.to_csv('mut_dupes.csv', index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "# remove duplicates, but keep first occurrence\n",
    "    mut_df = mut_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {mut_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "\n",
    "    \n",
    "# print(mut_df.columns)\n",
    "# # print(mut_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75f3d6c8-9257-4ac6-b883-75a967ba8592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT_ID', 'AGE', 'SEX', 'ETHNICITY'], dtype='object')\n",
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# clean patient data\n",
    "# print(patient_df.shape)\n",
    "# print(patient_df.columns)\n",
    "\n",
    "# subset data\n",
    "# subset for necessary columns\n",
    "patient_df = init_patient_df.filter(['PATIENT_ID',\n",
    "                        'AGE',\n",
    "                        'SEX', \n",
    "                        'ETHNICITY',\n",
    "                        'Consequence'\n",
    "                       ], axis=1)\n",
    "\n",
    "print(patient_df.columns)\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = patient_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(patient_df[patient_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    patient_df = patient_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {patient_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb2499e2-affb-404e-b970-04aa20bef06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATIENT_ID', 'SAMPLE_ID', 'SAMPLE_CLASS', 'ONCOTREE_CODE',\n",
      "       'CANCER_TYPE', 'CANCER_TYPE_DETAILED', 'TMB_NONSYNONYMOUS'],\n",
      "      dtype='object')\n",
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# clean sample data\n",
    "\n",
    "# print(sample_df.shape)\n",
    "# print(sample_df.columns)\n",
    "# print(sample_df.head())\n",
    "\n",
    "\n",
    "# subset data\n",
    "# subset for necessary columns\n",
    "sample_df = init_sample_df.filter(['PATIENT_ID',\n",
    "                                     'SAMPLE_ID',\n",
    "                                     'SAMPLE_CLASS',\n",
    "                                     'ONCOTREE_CODE',\n",
    "                                     'CANCER_TYPE',\n",
    "                                     'CANCER_TYPE_DETAILED',\n",
    "                                     'TMB_NONSYNONYMOUS'\n",
    "                                    ], axis=1)\n",
    "\n",
    "\n",
    "print(sample_df.columns)\n",
    "\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = sample_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(sample_df[sample_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    sample_df = sample_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {sample_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca4cd556-6160-44dd-9c56-f7f27a387f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataframes\n",
    "## TODO: redo so that all columns are available and that records with no samples will be there. \"left outer join\"? will get NAs.\n",
    "\n",
    "init_combined_df = mut_df.merge(sample_df, on='SAMPLE_ID', how='left')\n",
    "\n",
    "# print(mut_df.columns)\n",
    "# print(mut_df.shape)\n",
    "\n",
    "# print(sample_df.columns)\n",
    "# print(sample_df.shape)\n",
    "\n",
    "# print(init_combined_df.columns)\n",
    "# print(init_combined_df.shape)\n",
    "\n",
    "#add patient_df\n",
    "combined_df = init_combined_df.merge(patient_df, on='PATIENT_ID', how='left')\n",
    "\n",
    "# print(patient_df.columns)\n",
    "# print(patient_df.shape)\n",
    "\n",
    "# print(combined_df.columns)\n",
    "# print(combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c2fd3ee-02fc-48bf-acc9-7675137eea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add column for study id\n",
    "study_id = init_study_meta.iloc[0, 0]\n",
    "study_id = study_id.replace('cancer_study_identifier: ', '')\n",
    "# study_id\n",
    "combined_df['STUDY_ID'] = study_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aee6b500-7a61-4190-934b-53c7055686b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows : 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check duplicate count\n",
    "num_duplicates = combined_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows : {num_duplicates}\")\n",
    "\n",
    "# print duplicates (excluding first instance)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate rows (excluding first instance):\")\n",
    "    print(combined_df[combined_df.duplicated()])\n",
    "\n",
    "# # print full duplicate groups (including the first occurrences)\n",
    "#     print(\"\\nAll rows involved in duplication:\")\n",
    "#     print(mut_df[mut_df.duplicated(keep=False)])\n",
    "\n",
    "# remove duplicates, but keep first occurrence\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    print(f\"\\nDataFrame shape after removing duplicates: {combined_df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b0bcca1-476e-4e77-a0a1-bb3a3bab9b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (14737, 27)\n",
      "Removed 3123 rows where SAMPLE_CLASS == 'Cell line'\n",
      "New shape: (11614, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SAMPLE_CLASS\n",
       "Cell line    3123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# remove cell lines\n",
    "\n",
    "original_shape = combined_df.shape\n",
    "print(f\"Original shape: {original_shape}\")\n",
    "\n",
    "#lines to remove\n",
    "removed_df = combined_df[combined_df['SAMPLE_CLASS'] == 'Cell line']\n",
    "\n",
    "# remove cell lines\n",
    "filtered_df = combined_df[combined_df['SAMPLE_CLASS'] != 'Cell line']\n",
    "\n",
    "# calculate how many rows were removed\n",
    "rows_removed = original_shape[0] - filtered_df.shape[0]\n",
    "print(f\"Removed {rows_removed} rows where SAMPLE_CLASS == 'Cell line'\")\n",
    "\n",
    "# print new shape\n",
    "print(f\"New shape: {filtered_df.shape}\")\n",
    "\n",
    "# reassign df\n",
    "combined_df = filtered_df\n",
    "\n",
    "removed_df.to_csv('cell_lines_removed.csv', index=False)\n",
    "removed_df.value_counts(\"SAMPLE_CLASS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96f130c2-8fd1-481b-8f5a-00db0ded9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Value counts written for 27 columns to folder: value_counts_by_column\n"
     ]
    }
   ],
   "source": [
    "# combined_df.isna().sum()\n",
    "\n",
    "# Hugo_Symbol                   0\n",
    "# Chromosome                    0\n",
    "# Start_Position                0\n",
    "# End_Position                  0\n",
    "# Consequence                 124 - some of the Variant_Classification=Silent have no consequence described\n",
    "# Variant_Classification        0\n",
    "# Variant_Type                  0\n",
    "# Reference_Allele              0\n",
    "# Tumor_Seq_Allele2             0\n",
    "# SAMPLE_ID                     0\n",
    "# Sequence_Source               0\n",
    "# HGVSc                       136 - some of the Variant_Classification=Silent and all of the Variant_Classification=3'Flank and 5'Flank\n",
    "# HGVSp                       346 \n",
    "# Transcript_ID               124 - some of the Variant_Classification=Silent have no Transcript_ID described\n",
    "# RefSeq                     1338\n",
    "# Protein_position            334\n",
    "# Gnomad_Notation               0\n",
    "# PATIENT_ID                    0\n",
    "# SAMPLE_CLASS                  0\n",
    "# ONCOTREE_CODE                 0\n",
    "# CANCER_TYPE                   0\n",
    "# CANCER_TYPE_DETAILED          0\n",
    "# TMB_NONSYNONYMOUS             0\n",
    "# AGE                        4745 - some ages undisclosed\n",
    "# SEX                           0\n",
    "# ETHNICITY                 10900 - many patients' ethnicities undisclosed\n",
    "# STUDY_ID                      0\n",
    "\n",
    "\n",
    "# define output folder (will create it if needed)\n",
    "output_dir = \"value_counts_by_column\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# loop through each column\n",
    "for col in combined_df.columns:\n",
    "    # build filename\n",
    "    filename = f\"value_counts_{col}.txt\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # write counts to file\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(f\"Value counts for column: {col}\\n\\n\")\n",
    "        f.write(combined_df[col].value_counts(dropna=False).to_string())\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"✅ Value counts written for {len(combined_df.columns)} columns to folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b032d44-fcdd-45c1-b4cb-6d42c6b23894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hugo_Symbol                  0\n",
       "Chromosome                   0\n",
       "Start_Position               0\n",
       "End_Position                 0\n",
       "Consequence                  0\n",
       "Variant_Classification       0\n",
       "Variant_Type                 0\n",
       "Reference_Allele             0\n",
       "Tumor_Seq_Allele2            0\n",
       "SAMPLE_ID                    0\n",
       "Sequence_Source              0\n",
       "HGVSc                      136\n",
       "HGVSp                      346\n",
       "HGVSp_Short                136\n",
       "Transcript_ID              124\n",
       "RefSeq                    1338\n",
       "Protein_position           334\n",
       "PATIENT_ID                   0\n",
       "SAMPLE_CLASS                 0\n",
       "ONCOTREE_CODE                0\n",
       "CANCER_TYPE                  0\n",
       "CANCER_TYPE_DETAILED         0\n",
       "TMB_NONSYNONYMOUS            0\n",
       "AGE                          0\n",
       "SEX                          0\n",
       "ETHNICITY                    0\n",
       "STUDY_ID                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filling in NaNs - AGE, ETHNICITY, Consequence\n",
    "# TODO add consequence with annotation\n",
    "\n",
    "cols_to_fill = ['Consequence', 'AGE', 'ETHNICITY']\n",
    "fill_value = \"No_Data\"\n",
    "\n",
    "for col in cols_to_fill:\n",
    "    combined_df[col] = combined_df[col].fillna(fill_value)\n",
    "\n",
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2184b27-ab42-4734-8994-e4ab1d235d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting chromosome 23 to chromosome X or Y\n",
    "\n",
    "# TODO. look at gene and see whether it maps to x or y for males\n",
    "\n",
    "# female chromosome 23\n",
    "combined_df.loc[combined_df.SEX == \"Female\", 'Chromosome'] = \"X\"\n",
    "\n",
    "# male samples \n",
    "\n",
    "# duplicate each Male 23 variant, set to X or Y Chromosome, then run through VICC variation normalizer, see which tokenizes. \n",
    "# cross reference gene back to dataframe. If it is the wrong one, could be that there is an overlapping gene\n",
    "# find the rows to duplicate\n",
    "# chr23_rows = combined_df[combined_df['Chromosome'] == 23]\n",
    "# # change Chromosome to Y for subset\n",
    "# chr23_rows.loc[chr23_rows.SEX == \"Male\", 'Chromosome'] = \"Y\"\n",
    "# # append them to the original DataFrame\n",
    "# combined_df_male_dup = pd.concat([combined_df, chr23_rows], ignore_index=True)\n",
    "# # change orig male chrom23s to X\n",
    "# combined_df_male_dup.loc[combined_df_male_dup.SEX == \"Male\", 'Chromosome'] = \"X\"\n",
    "# #check for duplicates\n",
    "# duplicates = combined_df_male_dup[combined_df_male_dup.duplicated()]\n",
    "# print(duplicates.shape)\n",
    "# # reassign dataframe\n",
    "# combined_df = combined_df_male_dup\n",
    "\n",
    "\n",
    "# construct Gnomad variant ID column\n",
    "combined_df[\"Gnomad_Notation\"] = combined_df.apply(\n",
    "    lambda row: f\"{row['Chromosome']}-{row['Start_Position']}-{row['Reference_Allele']}-{row['Tumor_Seq_Allele2']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# run through VICC variant normalizer\n",
    "# 1) Keep your original dataframe intact\n",
    "mask_23_male = (combined_df['Chromosome'] == 23) & (combined_df['SEX'] == 'Male')\n",
    "ambig = combined_df.loc[mask_23_male].copy()\n",
    "\n",
    "# 2) Duplicate **just those** rows\n",
    "ambig_x = ambig.copy()\n",
    "ambig_y = ambig.copy()\n",
    "\n",
    "ambig_x['Chromosome'] = 'X'\n",
    "ambig_y['Chromosome'] = 'Y'\n",
    "\n",
    "# 3) Re-create Gnomad_Notation so it matches the new chromosome\n",
    "for frame in (ambig_x, ambig_y):\n",
    "    frame['Gnomad_Notation'] = (\n",
    "        frame['Chromosome'].astype(str) + '-' +\n",
    "        frame['Start_Position'].astype(str) + '-' +\n",
    "        frame['Reference_Allele'] + '-' +\n",
    "        frame['Tumor_Seq_Allele2']\n",
    "    )\n",
    "\n",
    "# 4) Append back if you really want both possibilities in the same table\n",
    "combined_df = pd.concat([combined_df, ambig_x, ambig_y], ignore_index=True)\n",
    "\n",
    "# validate notation\n",
    "bad_rows = combined_df[\n",
    "    combined_df['Gnomad_Notation'].str.split('-', n=1).str[0] !=\n",
    "    combined_df['Chromosome'].astype(str)\n",
    "]\n",
    "if not bad_rows.empty:\n",
    "    print(\"⚠️  Mismatch between Chromosome and Gnomad_Notation:\")\n",
    "    print(bad_rows[['Chromosome', 'Gnomad_Notation', 'SAMPLE_ID']].head())\n",
    "\n",
    "\n",
    "# rate limit and catch 4xx/5xx\n",
    "def fetch_symbol(notation, assembly='GRCh37', sleep=0.2):\n",
    "    url = f\"https://normalize.cancervariants.org/variation/{notation}\"\n",
    "    r = requests.get(url, params={'assembly': assembly}, timeout=10)\n",
    "    if r.status_code == 200:\n",
    "        return r.json().get('gene_context', {}).get('gene_symbol')\n",
    "    elif r.status_code == 403:\n",
    "        print(f\"[403] impossible coordinate for {notation}\")\n",
    "    elif r.status_code == 429:\n",
    "        print(\"[429] throttled, backing off…\"); time.sleep(2)\n",
    "    else:\n",
    "        print(f\"[{r.status_code}] error for {notation}\")\n",
    "    time.sleep(sleep)\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# write to file\n",
    "combined_df.to_csv('output2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99608997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131ab23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d56ef311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 134 rows with duplicated Gnomad_Notation per PATIENT_ID.\n"
     ]
    }
   ],
   "source": [
    "# remove variant dupes per patient\n",
    "\n",
    "# find duplicated (PATIENT_ID, Gnomad_Notation) pairs\n",
    "dupe_mask = combined_df.duplicated(subset=[\"PATIENT_ID\", \"Gnomad_Notation\"], keep=\"first\")\n",
    "# new DataFrame with the duplicated rows\n",
    "patient_variant_dupes = combined_df[dupe_mask]\n",
    "# remove those rows from the original DataFrame\n",
    "combined_df_cleaned = combined_df[~dupe_mask]\n",
    "# write removed rows to file\n",
    "patient_variant_dupes.to_csv(\"patient_variant_dupes.csv\", index=False)\n",
    "# print the number of rows removed\n",
    "print(f\"Removed {patient_variant_dupes.shape[0]} rows with duplicated Gnomad_Notation per PATIENT_ID.\")\n",
    "# reassign dataframe:\n",
    "combined_df = combined_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a1e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
